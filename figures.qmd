---
title: "Reanalysis of Demarchi et al. (2019)"
filters:
   - lightbox
lightbox:
  match: auto
  effect: none
format: 
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    fig-align: center
    
editor: visual
bibliography: references.bib
---

# Prepare

## Libraries

```{r}
library(expm)
library(patchwork)
library(magrittr)
library(tidyverse)

library(reticulate)
np <- import("numpy")
os <- import("os")
mne <- import("mne")

theme_set(theme_minimal())
theme_update(text = element_text(family = "Arial"))

path.root <- "./data/results"
list.subj <- list.dirs(path.root, full.names = F, recursive = F)
n.subj <- length(list.subj)

save <- FALSE
```

## Functions

### Matrix to df

```{r}
# matrix_to_df <- function(array, row.name = "t_train", col.name = "t_test", val.name = "value") {
#   array %>% 
#     as_tibble() %>%
#     rownames_to_column("t_train") %>%
#     pivot_longer(-t_train, names_to = "t_test", values_to = "value") %>% 
#     mutate(t_test = str_remove(t_test, "V")) %>% 
#     mutate(across(starts_with("t_"), ~(10*(as.numeric(.)-1)-700))) %>% 
#     return
# }

matrix_to_df2 <- function(array, row.name, col.name, val.name) {
  array %>% 
    as_tibble() %>%
    rownames_to_column(row.name) %>%
    pivot_longer(-row.name, names_to = col.name, values_to = val.name) %>% 
    mutate("{col.name}" := str_remove(!!sym(col.name), "V")) %>% 
    mutate_all(as.numeric) %>% 
    return
}

# !!! USE as.data.frame.table() instead
```

### Batch data loading

```{r}
load_loop_subj <- function(folder, condition, group.mean = T, diag = F) {
  array.scores <- array(dim = c(141,141,n.subj))
  i <- 1
  for (s in list.subj) {
    tmp <- os$path$join(path.root, s, folder,
                        paste0("cv_", condition, "_scores.npy"))
    
    # Proceed to next subject if file doesn't exist
    if (!os$path$isfile(tmp)) {next}
    
    # Load data otherwise
    tmp <- np$load(tmp)
    
    # Average across CV folds if present
    if (length(dim(tmp)) == 3) {
      tmp <- tmp %>% apply(c(2,3), mean) # average across CV folds
    }
      
    array.scores[,,i] <- tmp
    i <- i+1
  }
  
  # Return a dataframe
  # --- average across participants if requested (default)
  if (group.mean) {
    array.scores %>% 
      apply(c(1,2), mean) %>%
      matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") -> df.out
  # --- or participant-level data, with a subject identifier column
  } else {
    if (diag) {
      df.out <- tibble()
      for (i in 1:n.subj) {
        df.out %<>% bind_rows(
          array.scores[,,i] %>%
            matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") %>%
            filter(t_train == t_test) %>% mutate(id = list.subj[[i]])
        )
      }
    }
  }
  
  # Crop subject-level data for cluster analysis
  array.scores <- array.scores[70:nrow(array.scores),,]
  return(list(array.scores, df.out))
}
```

### Cluster permutation stats

```{r}
get_signif_clust2d <- function(X, n_permutations = 2**12, n_jobs = -1) {
  # run permutaiton tests
  mne$stats$spatio_temporal_cluster_1samp_test(X,
                                               n_permutations = n_permutations,
                                               n_jobs = as.integer(n_jobs),
                                               out_type = "mask") -> tmp
  names(tmp) <- c("t_obs","clusters","cluster_pv","H0")
  
  # Extract clusters: the final output is a 0/1 matrix, 1 indicating belonging to a significant cluster 
  # --- get ids of significant clusters
  idx.signif <- which(tmp$cluster_pv < .05) 
  # --- aggregate clusters
  signif <- array(0, dim = dim(tmp$t_obs)) 
  for (i in idx.signif) {
    signif <- signif + tmp$clusters[[i]]
  }
  
  return(1*(signif > 0))
}


# Loop through multiple conditions, stored in a dataframe where each row contains a 2D array in an "array" column
# Other columns are appended to the output as descriptors of the condition
cluster_loop_cond <- function(df, H0 = 0.25, n_permutations = 2**12, n_jobs = -1) {
  # Initialize significant clusters dataframe
  df.clusters <- tibble()
  # Loop through all conditions
  for (i in 1:nrow(df)) {
    
    # Extract array of subject-level time-generalized accuracy
    X <- df[[i,"array"]][[1]] %>% 
      # --- reshape to how MNE expects it
      np$moveaxis(as.integer(2), as.integer(0)) 
  
    df.clusters %<>% bind_rows(
      get_signif_clust2d(X-H0, n_jobs = n_jobs, n_permutations = n_permutations) %>% 
        matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "signif") %>% 
        bind_cols(select(df,-array)[i,])
    )
  }
  
  return(df.clusters)
}
```

### Base plot

```{r}
plot.base <- function(df.plot,
                      col.pal = rev(pals::brewer.rdbu(10)),
                      acc.breaks = acc.breaks.base, acc.labels = acc.labels.base) {
  
  # Onset lines
  lines.v.pos <- 330*seq(round(min(df.plot$t_test)/333), round(max(df.plot$t_test)/333), 1)
  lines.v.pos <- lines.v.pos[lines.v.pos!=0]
  lines.h.pos <- 330*seq(round(min(df.plot$t_train)/333), round(max(df.plot$t_train)/333), 1)
  lines.h.pos <- lines.h.pos[lines.h.pos!=0]

  # Plot
  df.plot %>% 
    ggplot(aes(x = t_test, y = t_train)) +
    # --- heatmap
    geom_tile(aes(fill = accuracy)) +
    # --- significant clusters
    geom_contour(aes(z = signif), size = 0.1, color = col.clusters) +
    # --- sounds onsets
    geom_vline(xintercept = lines.v.pos, linetype = 2, color = col.lines) +
    geom_hline(yintercept = lines.h.pos, linetype = 2, color = col.lines) +
    geom_vline(xintercept = 0, color = col.lines) +
    geom_hline(yintercept = 0, color = col.lines) +
    
    scale_x_continuous(name = "Test time (ms)",
                       breaks = scales::pretty_breaks(10),
                       expand = c(0,0)) +
    scale_y_continuous(name = "Train time (ms)",
                       breaks = scales::pretty_breaks(10),
                       expand = c(0,0)) +
    scale_fill_stepsn(name = "Accuracy",
                      colors = col.pal,
                      breaks = acc.breaks,
                      labels = acc.labels,
                      limits = c(min(acc.breaks), max(acc.breaks)),
                      oob = scales::squish) +
    coord_equal() +
    guides(fill = guide_colorbar(barwidth = 0.5*length(acc.breaks-1), barheight = 0.5,
                                 ticks = F, title.vjust = 1)) +
    theme(# Text size
          plot.title = element_text(size = 12, hjust = 0.5, face = "bold"),
          plot.subtitle = element_text(size = 9, hjust = 0.5),
          axis.title = element_text(size = 9),
          legend.title = element_text(size = 9),
          strip.text = element_text(size = 9),
          axis.text = element_text(size = 5),
          legend.text = element_text(size = 5.5),
          # Time ticks
          axis.ticks = element_line(color = "black"),
          axis.ticks.length = unit(0.1, "cm"),
          # Legend
          legend.position = "bottom",
          legend.box.margin = margin(0,0,0,0),
          legend.box.spacing = unit(0, "pt"),
          # no grid
          panel.grid = element_blank()) %>% 
    return
}
```

## Parameters

### Transition matrices

From @demarchi2019

```{r}

mat.T <- list(RD = matrix(rep(.25, 16), ncol = 4, byrow = T),
              MM = matrix(), MP = matrix(), OR = matrix())

mat.T$MM <- matrix(c(c(.25,0,.375,.375),
                     c(.375,.25,0,.375),
                     c(.375,.375,.25,0),
                     c(0,.375,.375,.25)),
                   ncol = 4, byrow = T)

mat.T$MP <- matrix(c(c(.25,0,.15,.60),
                     c(.60,.25,0,.15),
                     c(.15,.60,.25,0),
                     c(0,.15,.60,.25)),
                   ncol = 4, byrow = T)

mat.T$OR <- matrix(c(c(.25,0,0,.75),
                     c(.75,.25,0,0),
                     c(0,.75,.25,0),
                     c(0,0,.75,.25)),
                   ncol = 4, byrow = T)
```

### Plotting

```{r}
# Temporal resolution in ms (1000 / sampling frequency)
dt <- 10

# Colors
col.pal.base <- rev(pals::brewer.rdbu(10))
col.pal.diff <- rev(pals::brewer.brbg(10))
col.lines <- "grey40"
col.clusters <- "grey20"

# Breaks & Labels
# --- function
format_labels_acc <- function(labels) {
  labels[seq(2,length(labels),2)] <- ""
  labels <- str_replace(labels, "0.", ".")
}
# --- base
acc.breaks.base <- seq(.21,.29, .005)
acc.labels.base <- format_labels_acc(acc.breaks.base)
# --- diff
acc.breaks.diff <- seq(-.02,.02, .005)
acc.labels.diff <- format_labels_acc(acc.breaks.diff)
```

# Figures

## Figure 1

### Pitches

```{r}
#| fig-width: 1
#| fig-height: 2
#| output: false
df.plot.pitch <- tibble(pitch = c(200,430,928,2000))

df.plot.pitch %>% 
  ggplot(aes(x = 1, y = pitch, color = (pitch))) +
  geom_point(size = 4, show.legend = F) +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(name = "Pitch (Hz)",
                     breaks = df.plot.pitch$pitch) +
  scale_color_viridis_c(name = "Pitch (Hz)",
                        breaks = (df.plot.pitch$pitch),
                        trans = "log") +
  coord_cartesian(clip = "off") +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        panel.grid = element_blank(),
        panel.grid.major.y = element_line()) -> g.pitch

g.pitch
```

```{r}
#| eval: false
#| fig-width: 1
#| fig-height: 2
df.plot.pitch <- tibble(pitch = c(200,430,928,2000))

df.plot.pitch %>% 
  ggplot(aes(x = 1, y = pitch, color = (pitch))) +
  geom_point(size = 6) +
  scale_x_continuous(expand = c(0,0)) +
  scale_color_viridis_c(name = "Pitch (Hz)",
                        breaks = (df.plot.pitch$pitch),
                        trans = "log") +
  guides(color = guide_colorbar(title.hjust = 1,
                                label.position = "left",
                                label.vjust = c(0,0.5,0.5,1),
                                barwidth = 0.5, barheight = 8)) +
  coord_trans(y = scales::log_trans(),
              ylim = c(200/2.15, 2000*2.15),
              clip = "off") +
  theme_void() +
  theme(legend.position = "left",
        legend.box.margin = margin(b = 15, r=-20)) -> g.pitch2

g.pitch2

```

### Transition matrices

```{r}
#| output: false

# Convert & combine transition matrices into a dataframe
df.plot <- tibble()
for (condition in c("RD","MM","MP","OR")) {
  df.plot %<>% bind_rows(
    mat.T[[condition]] %>% 
      matrix_to_df2(row.name = "from", col.name = "to", val.name = "p") %>% 
      mutate(condition = condition)
  )  
}
df.plot %<>%
  mutate(condition = factor(condition, names(mat.T)))

# Plot
df.plot %>% 
  ggplot(aes(x = to, y = from)) +
  facet_wrap(~ condition, nrow = 1, strip.position = "bottom") +
  # --- heatmap
  geom_tile(aes(fill = p)) +
  # --- display percentages
  geom_text(data = . %>% filter(p<=.25),
            aes(label = paste0(100*p,"%")),
            color = "black", size = 2) +
  geom_text(data = . %>% filter(p>.25),
            aes(label = paste0(100*p,"%")),
            color = "white", size = 2) +
  # --- display color-coded pitch in axes
  geom_point(data = bind_rows(tibble(x = 0.1, y = 1:4, pitch = 1:4),
                              tibble(y = 0.1, x = 1:4, pitch = 1:4)),
             aes(x, y, color = pitch), size = 4, show.legend = FALSE) +
  
  scale_color_viridis_c() +
  scale_x_continuous(name = "...to...\n", position = "top") +
  scale_y_reverse(name = "from...\n") +
  scale_fill_gradient(name = "transition probability",
                      low = "white", high = "black",
                      labels = ~str_replace(., "^0.","."),
                      limits = c(0,1)) +
  guides(fill = guide_colorbar(barheight = 0.5,
                               ticks = F, title.vjust = 1)) +
  coord_equal(xlim = c(0.5,4.5), ylim = rev(c(0.5,4.5)),
              expand = F, clip = "off") +
  theme(legend.position = "bottom",
        legend.box.margin = margin(t = -20),
        # text size
        axis.title = element_text(size = 9),
        legend.title = element_text(size = 9),
        strip.text = element_text(size = 12),
        # remove axis text
        axis.text = element_blank(),
        # Positions & margins
        axis.title.x = element_text(hjust = 0.08),
        panel.spacing.x = unit(0.8,"cm")) -> g.transitions
```

### Reordering

```{r}
#| output: false

# Generate Markov sequences
n.samples <- 12
stims <- list(RD = c(), OR = c())
set.seed(128764) #20476, 99713
for (entropy in c("RD","OR")) {
  stims[[entropy]] <- vector("numeric", n.samples)
  stims[[entropy]][1] <- sample(1:4, 1)
  for (i in 2:n.samples) {
    stims[[entropy]][i] <- sample(1:4, 1, prob = mat.T[[entropy]][stims[[entropy]][i-1],])
  }
}

# Add global sequence indices, class-specific indices and offset according to pitch
df.plot <- stims %>% as.tibble() %>% 
  mutate(idx = as.double(1:n.samples)) %>% 
  pivot_longer(-idx, names_to = "entropy", values_to = "class") %>% 
  mutate(entropy = factor(entropy, levels = c("OR","RD"))) %>%
  group_by(entropy,class) %>% mutate(rank = rank(idx)) %>% 
  mutate(y = as.double(entropy) + class/16-10/64)

# Plot
df.plot %>% 
  ggplot(aes(x = idx, y = y, color = class)) +
  ggh4x::geom_pointpath(data = df.plot %>% arrange(desc(entropy)),
               aes(x = idx, y = y, group = interaction(class,rank)),
               mult = 0.4, color = "black", linewidth = 0.3,
               arrow = arrow(length=unit(.2, 'cm'))) +
  geom_point(size = 4, show.legend = F) +
  geom_text(aes(label = rank), size = 2, color = "white") +
  scale_x_continuous(name = "sequence index", breaks = 1:n.samples) +
  scale_y_continuous(breaks = c(1,2), labels = c("OR","RD"), position = "left") +
  scale_color_viridis_c() +
  coord_cartesian(clip = "off") +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_text(size = 12, color = "black"),
        axis.title.x = element_text(size = 9, color = "black"),
        panel.grid = element_blank(),
        panel.grid.major.x = element_line(color = "grey80", linewidth = 0.2)) -> g.reordering

g.reordering
```

### Prediction types

Presented vs. most likely

```{r}
#| output: false

# Generate Markov sequences
n.samples <- 6
stims <- mat.T
set.seed(62498) #128764
for (entropy in names(stims)) {
  stims[[entropy]] <- vector("numeric", n.samples)
  stims[[entropy]][1] <- 4#sample(1:4, 1)
  for (i in 2:n.samples) {
    stims[[entropy]][i] <- sample(1:4, 1, prob = mat.T[[entropy]][stims[[entropy]][i-1],])
  }
}

# Add sequence index & predictions
df.plot <- stims %>% as.tibble() %>% 
  mutate(idx = as.double(1:n.samples)) %>% 
  pivot_longer(-idx, names_to = "entropy", values_to = "class") %>% 
  mutate(entropy = factor(entropy, levels = names(stims))) %>% 
  group_by(entropy) %>% mutate(actual = lead(class),
                               mostlikely = ifelse(class==1, 4, class-1)) %>% 
  pivot_longer(c(actual,mostlikely), names_to = "prediction", values_to = "class.pred")

# Plot
df.plot %>% 
  ggplot(aes(x = idx, y = class)) +
  facet_wrap(~ entropy, nrow = 2, strip.position = "right") +
  geom_point(aes(fill = class), size = 2, shape = 21, show.legend = F) +
  geom_point(data = df.plot %>% filter(prediction == "mostlikely", idx != n.samples),
             aes(x = idx+1, y = class.pred), size = 2, shape = 8) +
  scale_x_continuous(name = "sequence index", breaks = 1:n.samples) +
  scale_y_continuous(name = "") +
  scale_fill_viridis_c() +
  coord_cartesian(clip = "off") +
  expand_limits(x = c(0.9,6.1), y = c(0.3,4.7)) +
  theme(panel.border = element_rect(fill=NA),
        axis.text.y = element_blank(),
        axis.title.x = element_text(size = 9, color = "black"),
        strip.text = element_text(size = 12),
        panel.spacing = unit(0.2,"cm"),
        panel.grid = element_blank()) -> g.mostlikely

g.mostlikely
```

### Assemble

```{r}
#| fig-width: 8
#| fig-height: 4.5
#| column: page
#| lightbox:
#|   group: r-graph

((g.pitch + labs(title = "")) +
    plot_spacer() +
    (g.transitions + labs(title = "Transition matrices")) +
    plot_layout(widths = c(0.5,0.2,15))) / (
wrap_elements(full = g.reordering + labs(title="Reordering of random data")) +
   plot_spacer() +
   (g.mostlikely + labs(title="Predictions")) +
  plot_layout(widths = c(1,0.05,1))
) + 
  plot_layout(heights = c(1.4,1)) +
  plot_annotation(tag_levels = "a") &
  
  theme(plot.title = element_text(size = 12),
        plot.title.position = "panel",
        plot.tag.position = c(0, 1),
        plot.tag = element_text(size = 14, hjust = 0, vjust = 1, face = "bold")) -> g

g

if (save) {
  g %>% ggsave(filename = "./figures/fig1.png", width = 8, height = 4.5, dpi = 300, device = ragg::agg_png)
}
```

**Figure 1.** Original experimental design and reanalyses. **(a)** Demarchi et al. (2019) presented four different pure sinusoidal tones, logarithmically spaced in pitch. **(b)** Four types of sequences of sounds were generated, each using a Markov chain characterized by a distinct transition matrix. The transition matrices were manipulated so that (i) probabilities of repetitions (diagonal elements) were the same across sounds and sequences, (ii) the identity of the most likely next sound was the same in all sequences, and (iii) the entropy of the generated sequences decreased from RD (random) to MM (midminus), to MP (midplus) to OR (ordered). **(c)** In our reanalysis, we created a new control dataset by reordering epochs from randomly sequences according to the sequence order of higher entropy conditions (here, OR). By construction, any above chance level decoding accuracy on this control dataset could only be attributed to sequence effects and not to brain representations. (d) Demarchi et al. (2019) decoded the sound that was actually presented to the participants (colored circles), which was not always the most likely one given the previous stimulus (asterisks); the lower the entropy, the more discrepancy between the two. In our reanalysis, we decoded both types of prediction.

## Figure 2

### Load stimulus data

```{r}
#| cache: true

# Load subject-level data and derive grand average
df.stim.mean <- tibble()
df.stim.subj <- tibble()
for (manip in c("","_reord")) { 
  
  for (direction in c("rd_to_rd", "rd_to_mm", "rd_to_mp", "rd_to_or")) {
    tmp <- load_loop_subj(folder = "reorder_random",
                          condition = paste0(direction, manip))
    
    df.stim.subj %<>% bind_rows(tibble(manip = manip, direction = direction, array = list(tmp[[1]])))
    df.stim.mean %<>% bind_rows(tmp[[2]] %>% mutate(manip = manip, direction = direction))
  }
}
```

### Load omission data

```{r}
#| cache: true

df.omit.mean <- tibble()
df.omit.subj <- tibble()
for (manip in c("","_reord")) { 
  
  for (direction in c("rd_to_rd", "rd_to_mm", "rd_to_mp", "rd_to_or")) {
      
    tmp <- load_loop_subj(folder = "reorder_random_omission",
                          condition = paste0(direction, manip))
    
    df.omit.subj %<>% bind_rows(tibble(manip = manip, direction = direction, array = list(tmp[[1]])))
    df.omit.mean %<>% bind_rows(tmp[[2]] %>% mutate(manip = manip, direction = direction))
  }
}
```

### Clusters stats & diff

```{r}
#| cache: true
#| 
# Cluster analysis
# --- sounds
df.clusters <- cluster_loop_cond(df.stim.subj, n_permutations = 2**5)
df.stim.mean %<>% left_join(df.clusters %>% mutate(t_train = t_train + 69))
# --- omissions
df.clusters <- cluster_loop_cond(df.omit.subj, n_permutations = 2**5)
df.omit.mean %<>% left_join(df.clusters %>% mutate(t_train = t_train + 69))
# --- differences
# df.diff.subj



# Combine SOUNDS & OMISSIONS
df.plot <- bind_rows(df.stim.mean %>% mutate(stim = "sounds"),
                     df.omit.mean %>% mutate(stim = "omissions")) %>% 
  mutate(direction = toupper(sub("rd_to_", "", direction)),
         direction = factor(direction, levels = rev(c("RD","MM","MP","OR")))) %>%
  # --- convert indices to time
  mutate(across(starts_with("t_"), ~(dt*(.-1)-700))) %>% 
  # --- crop time
  filter(t_train>=0, (t_train-333) < dt)

# Calculate difference scores
df.diff <- df.plot %>% 
  mutate(manip = case_match(manip, "" ~ "original", "_reord" ~ "reordered")) %>% 
  pivot_wider(names_from = manip, values_from = accuracy) %>%
  mutate(accuracy = original - reordered,
         manip = toupper("original - reordered"))


```

### Plot

```{r}
#| fig-width: 8
#| fig-height: 7
#| column: page
#| lightbox:
#|   group: r-graph

g.base <- list(sound = c(), omission = c())
g.diff <- list(sound = c(), omission = c())

for (s in c("sounds","omissions")) {
  # ORIGINAL & REORDERED
  df.plot %>% 
    filter(stim == s) %>% 
    mutate(manip = case_match(manip, ""~"Test data: ORIGINAL",
                              "_reord"~"Test data: RANDOM REORDERED")) %>% 
    plot.base(col.pal = col.pal.base,
              acc.breaks = acc.breaks.base,
              acc.labels = acc.labels.base) +
    facet_grid(direction ~ manip) +
    labs(title = paste0(toupper(s), ", decoding presented")) -> g.base[[s]]
  
  # DIFFERENCE
  df.diff %>%
    filter(stim == s) %>% 
    plot.base(col.pal = col.pal.diff,
              acc.breaks = acc.breaks.diff,
              acc.labels = acc.labels.diff) +
    facet_grid(direction ~ manip) +
    labs(title = toupper(s)) +
    theme(axis.title.y = element_blank()) -> g.diff[[s]]
}

(g.base[["sounds"]] + g.diff[["sounds"]] + plot_layout(widths = c(2, 1))) /
  (g.base[["omissions"]] + g.diff[["omissions"]] + plot_layout(widths = c(2, 1))) +
  plot_annotation(tag_levels = c("a","b","c","d")) &
  theme(plot.tag.position = c(0, 1),
        plot.tag = element_text(size = 14, hjust = 0, vjust = 1, face = "bold")) -> g

g

if (save) {
  g %>% ggsave(filename = "./figures/fig2.png", width = 8, height = 7.5, dpi = 300, device = ragg::agg_png)
}
```

**Figure 2.** Time-generalization decoding of sounds presented in structured sequences with a classifier trained on random sound sequences. **(a, left)** replicates Demarchi et al. approach (figure 3a in the original publication) where above 25% chance level decoding appears possible several hundreds milliseconds before and after the stimulus. The design of our figure is different in two important aspects. First, we set up the color scale so as to reduce the saturation present in the original figure. Yet, in both the original and replicated analyses, the pre-stimulus decoding peaks in the highly regular condition (OR) at -230ms (i.e. approximately 100ms after the onset of the preceding sound) and exceeds the 25% chance level by less than 1 percentage point. Both analyses also reveal late post-stimulus decoding peaking slightly before 500ms after stimulus onset for train times around 100ms. Second, we have extended the testing time to cover the second stimulus before the target, which revealed below 25% chance level accuracy, suggesting that decoding performance was at least partly driven by statistical dependency between stimuli. **(a, right)** is the same analysis, carried out on random generated data re-ordered to mimic structured sequences (see Methods and fig. 1c). Pre-stimulus decoding is found again and **(b)** differentiation with the original results indicate that it is comparable in temporal pattern and magnitude. Residual pre-stimulus decoding is not statistically significant anymore, late post-stimulus decoding remains present. Note the negative diagonal during the decoded stimulus, which reflects the better tuning of the classifier to data coming from the random condition, as well as the positive upper diagonal during $S_{+1}$ which is due to cropping in reordered data. **(c,d)** Original and re-ordering analyses applied to omitted sounds (figure 3b in the original publication) lead to the same conclusions.

## Figure 3

### Load confusion matrices

```{r}
#| cache: true

null_accuracy <- function(mat.confusion, mat.transition) {
  # Calculate accuracy under the null hypothesis from the transition and confusion matrices mat.T and mat.C
  return(0.25 + sum(diag(cov(t(mat.transition), t(mat.confusion)))))
}

array.scores <- array(dim = c(34,136,n.subj))
tmp.all <- array(dim = c(34,34,4,4,n.subj))
i <- 1
for (s in list.subj) {
  
  # --- load the confusion matrix
  tmp.file <- os$path$join(path.root, s, "reorder_random",
                      "rd_to_rd_confmats.npz") %>% np$load()
  
  # --- crop around S0 (decoded stimulus)
  tmp <- tmp.file$f[["arr_0"]][,71:104,71:104,,] %>%
    apply(c(2,3,4,5), mean)
  
  # tmp.file$close()
  
  # --- append to other subjects
  tmp.all[,,,,i] <- tmp
  
  # NOTE: because the transition matrix is the same for all subjects, theoretical accuracy can be calculated from the group average of the confusion matrix (faster)
  # # --- calculate theoretical accuracy
  # #   --- for S-2
  # array.scores[,1:34,i] <- tmp %>% 
  #   apply(c(1,2), null_accuracy, mat.transition = mat.T.OR%^%2)
  # #   --- for S-1
  # array.scores[,35:68,i] <- tmp %>% 
  #   apply(c(1,2), null_accuracy, mat.transition = mat.T.OR%^%1)
    
  i <- i+1
}

# Average individual theoretical accuracies
# DEPRECATED: see note above
# df.maths <- array.scores %>% 
#   apply(c(1,2), mean) %>%
#   matrix_to_df

```

### Calculate

```{r}

# Average across participants
mat.C.mean <- tmp.all %>% apply(c(1,2,3,4), mean)

df.maths.all <- tibble()
for (condition in names(mat.T)) {
  df.maths.all %<>%
    # Theoretical results for stimulus "S minus 2"
    bind_rows(mat.C.mean %>%
                apply(c(1,2), null_accuracy, mat.transition = mat.T[[condition]]%^%2) %>%
                matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") %>% 
                mutate(condition = condition, stimulus = "S-2")
              ) %>% 
    # Theoretical results for stimulus "S minus 1"
    bind_rows(mat.C.mean %>%
                apply(c(1,2), null_accuracy, mat.transition = mat.T[[condition]]%^%1) %>%
                matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") %>% 
                mutate(condition = condition, stimulus = "S-1")
              ) %>% 
    # Theoretical results for stimulus "S+1"
    bind_rows(mat.C.mean %>%
                apply(c(1,2), null_accuracy, mat.transition = t(mat.T[[condition]])) %>%
                matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") %>% 
                mutate(condition = condition, stimulus = "S+1")
              )
}
```

### Plot

```{r}
#| fig-width: 8
#| fig-height: 4
#| column: page
#| lightbox:
#|   group: r-graph

df.plot <- df.maths.all %>% 
  mutate(across(starts_with("t_"), ~dt*(.-1))) %>% 
  mutate(t_test = t_test + 330*as.numeric(str_remove(stimulus,"S"))) %>%
  mutate(condition = factor(condition, levels = rev(names(mat.T))),
         stimulus = factor(stimulus, levels = c("S-2", "S-1", "S+1")))

col.lines <- "grey40"
lines.v.pos <- 330*seq(round(min(df.plot$t_test)/333), round(max(df.plot$t_test)/333), 1)
lines.v.pos <- lines.v.pos[lines.v.pos!=0]
lines.h.pos <- 330*seq(round(min(df.plot$t_train)/333), round(max(df.plot$t_train)/333), 1)
lines.h.pos <- lines.h.pos[lines.h.pos!=0]


df.plot %>% 
  plot.base() +
  facet_grid(condition ~ .) +
  labs(title = "Theoretical decoding accuracy",
       subtitle = "based on transition and confusion matrices") -> g

g

if (save) {
  g %>% ggsave(filename = "./figures/fig3.png", width = 8, height = 4, dpi = 300, device = ragg::agg_png)
}
```

**Figure 3.** Based on the transition matrix used to generate sequences of stimuli and the confusion matrix of a classifier trained on random sequence data, it is possible to calculate the expected accuracy of the classifier when tested on structured sequences. The results align closely with the accuracy measured from reordered random data (see figure 2a).

## Figure 4

### Load data

```{r}
#| cache: true

df.sp <- tibble()
for (manip in c("","_reord")) { 
  
  for (direction in c("rd_to_mm", "rd_to_mp", "rd_to_or")) {
    
    df.sp %<>% bind_rows(
      load_loop_subj(folder = "reorder_random",
                     condition = paste0(direction, "_sp", manip)) %>% 
        mutate(manip = manip, direction = direction)
    )
  }
}
```

### Prepare data

```{r}
# Combine SOUNDS & OMISSIONS
df.plot.sp <- df.sp %>% 
  mutate(direction = toupper(sub("rd_to_", "", direction)),
         direction = factor(direction, levels = rev(c("RD","MM","MP","OR")))) %>% 
  # --- convert indices to time
  mutate(across(starts_with("t_"), ~(dt*(.-1)-700))) %>% 
  # --- crop time
  filter(t_train>=0, (t_train-333) < dt)

# Calculate difference scores
df.diff.sp <- df.plot.sp %>% 
  mutate(manip = case_match(manip, "" ~ "original", "_reord" ~ "reordered")) %>% 
  pivot_wider(names_from = manip, values_from = accuracy) %>%
  mutate(accuracy = original - reordered,
         manip = toupper("original - reordered"))

# --- add average across entropy levels
df.diff.sp %<>% bind_rows(
  df.diff.sp %>% 
    group_by(t_train, t_test) %>% 
    summarise(accuracy = mean(accuracy, na.rm=T), .groups = "drop") %>% 
    mutate(direction = "average of\n(MM,MP,OR)",
           manip = toupper("original - reordered"))
  ) %>% 
  mutate(direction = factor(direction, levels = rev(c("average of\n(MM,MP,OR)","MM","MP","OR"))))

# Onset lines
col.lines <- "grey40"
lines.v.pos <- 333*seq(round(min(df.plot$t_test)/333), round(max(df.plot$t_test)/333),1)
lines.v.pos <- lines.v.pos[lines.v.pos!=0]
lines.h.pos <- 333*seq(round(min(df.plot$t_train)/333), round(max(df.plot$t_train)/333),1)
lines.h.pos <- lines.h.pos[lines.h.pos!=0]
```

### Plot

```{r}
#| fig-width: 8
#| fig-height: 4
#| column: page
#| lightbox:
#|   group: r-graph

# ORIGINAL & REORDERED
df.plot.sp %>% 
  mutate(manip = case_match(manip, ""~"Test data: ORIGINAL",
                            "_reord"~"Test data: RANDOM REORDERED")) %>% 
  plot.base(col.pal = col.pal.base,
            acc.breaks = acc.breaks.base,
            acc.labels = acc.labels.base) +
  facet_grid(direction ~ manip) +
  labs(title = paste0(toupper("sounds"), ", decoding most likely")) -> g.base

# DIFFERENCE
df.diff.sp %>%
  plot.base(col.pal = col.pal.diff,
            acc.breaks = acc.breaks.diff,
            acc.labels = acc.labels.diff) +
  facet_grid(direction ~ manip) +
  labs(title = toupper("sounds")) +
  theme(axis.title.y = element_blank(),
        strip.text = element_text(vjust = 0)) -> g.diff

# ASSEMBLE
(g.base + g.diff + plot_layout(widths = c(2, 1))) +
  plot_annotation(tag_levels = c("a","b")) &
  theme(plot.tag.position = c(0, 1),
        plot.tag = element_text(size = 14, hjust = 0, vjust = 1, face = "bold")) -> g

g

if (save) {
  g %>% ggsave(filename = "./figures/fig4.png", width = 8, height = 4, dpi = 300, device = ragg::agg_png)
}
```

**Figure 4.** Time-generalization decoding of the sound most likely to be presented at t=0, given the identity of the previous sound, with a classifier trained on random sequence data. Compared to the original approach (replicated here in figure 2a, left), this approach tests the more plausible hypothesis that the brain holds the strongest predictive representation for the most statistically likely stimulus, which is not always the actually presented one (see Methods and figure 1d). **(a)** Direct comparison of decoding performance with the 25% chance level appear to suggest negative performance, but this is largely due to statistical dependency between the the most likely and the actual sound, as is confirmed by decoding reordered random sequences. **(b)** After proper control of statistical dependency effects, a robust but weak (\<1% point) above chance level decoding remains between +80 and +230ms.

## Figure 5

### Load data

```{r}
#| cache: true

df.trainintest <- tibble()
for (manip in c("","_reord")) { 
  
  for (entropy in tolower(names(mat.T))) {
    
    df.trainintest %<>% bind_rows(
      load_loop_subj(folder = "reorder_random",
                     condition = paste0(entropy,"_to_",entropy,manip)) %>% 
        mutate(manip = manip, entropy = entropy)
    )
  }
}

df.trainintest.2 <- tibble()
for (manip in c("","_reord")) { 
  
  for (entropy in tolower(names(mat.T))) {
    
    df.trainintest.2 %<>% bind_rows(
      load_loop_subj(folder = "reorder_random",
                     condition = paste0(entropy,manip,"_to_",entropy,manip),
                     group.mean = FALSE, diag = TRUE) %>% 
        mutate(manip = manip, entropy = entropy)
    )
  }
}
```

### Prepare data

```{r}

# Factorize & filter
df.plot <- df.trainintest.2 %>% 
  mutate(entropy = factor(toupper(entropy), levels = rev(names(mat.T)))) %>% 
  # --- convert indices to time
  mutate(across(starts_with("t_"), ~(dt*(.-1)-700)))
  

# Add difference scores
df.plot %<>% 
  mutate(manip = case_match(manip, "" ~ "original", "_reord" ~ "reordered")) %>% 
  pivot_wider(names_from = manip, values_from = accuracy) %>%
  mutate(diff = original - reordered) %>% 
  pivot_longer(cols=c(original,reordered,diff),
               names_to = "manip", values_to = "accuracy") %>% 
  mutate(manip = (recode_factor(manip, original = "original", reordered = "reordered",
                                diff = "original - reordered",)))

# Calculate group mean & CIs
df.plot %<>%
  group_by(t_train, entropy, manip) %>% 
  summarise(accuracy.ci = sd(accuracy),
            accuracy.mean = mean(accuracy),
            .groups = "drop")
```

### Plot

This one trains on entropy data and tests on random-reordered:

```{r}
#| column: page
#| lightbox:
#|   group: r-graph

df.plot %>% 
  ggplot(aes(x = t_train, y = accuracy.mean, color = entropy, fill = entropy)) +
  facet_grid(manip ~ ., scales = "free_y") +
  geom_hline(data = tibble(manip = factor(c("original", "reordered", "original - reordered"),
                                          levels = levels(df.plot$manip)),
                           chance = c(.25, .25, 0)),
             aes(yintercept = chance)) +
  geom_ribbon(aes(ymin = accuracy.mean-accuracy.ci, ymax = accuracy.mean+accuracy.ci),
              color = NA,
              alpha = 0.3) +
  geom_line() +
  geom_vline(xintercept = 0, color = col.lines) +
  geom_vline(xintercept = 333*c(-2,-1,1,2), linetype = 2, color = col.lines)
```

**Figure 5.** Decoding of sounds in structured sequences with a classifier trained on the same sequences. During the presentation of the stimulus itself (t between 0 and 333ms), all classifiers have the exact same performance on random sequence data ??? \<- this is not expected: the random classifier should perform better than all others, as it is better tuned to random data (same logic than behind the negative diagonal in figure 2b)

# Supplementary figures

## Confusion matrices

```{r}
#| fig-width: 6
#| fig-height: 2
#| column: page
#| lightbox:
#|   group: r-graph

df.confusion <- tibble()
for (i in 1:dim(mat.C.mean)[1]) {
  df.confusion %<>% bind_rows(
    mat.C.mean[i,i,,] %>% matrix_to_df2("from", "to", "p") %>% mutate(t = i)
  )
}

df.confusion %>% 
  mutate(t = dt*(t-1)) %>% 
  filter(t%%30==0) %>% 
  ggplot(aes(x = to, y = from, fill = p)) +
  facet_wrap(~ t, ncol = 6, labeller = label_both, strip.position = "bottom") +
  geom_tile() + 
  scale_x_continuous(name = "predicted class", position = "top") +
  scale_y_reverse(name = "true class") +
  scale_fill_gradient(name = "transition probability",
                      low = "white", high = "black",
                      labels = ~str_replace(., "^0.","."),
                      limits = c(0.15,0.35), oob = scales::squish) +
  guides(fill = guide_colorbar(barwidth = 0.5,
                               ticks = F, title.vjust = 1)) +
  coord_equal(xlim = c(0.5,4.5), ylim = rev(c(0.5,4.5)),
              expand = F, clip = "off") +
  theme()
```
