---
title: "Reanalysis of Demarchi et al. (2019)"
filters:
   - lightbox
lightbox:
  match: auto
  effect: none
format: 
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    fig-align: center
    
editor: visual
bibliography: references.bib
---

# Prepare

## Libraries

```{r}
library(expm)
library(patchwork)    # combine plots
library(magrittr)     # special pipes
library(tictoc)       # time executions
library(correlation)
library(abind)        # combine multi-dimensional arrays

library(tidyverse)

library(reticulate)
np <- import("numpy")
os <- import("os")
mne <- import("mne")

theme_set(theme_minimal())
theme_update(text = element_text(family = "Arial"))

path.root <- "./data/results"
list.subj <- list.dirs(path.root, full.names = F, recursive = F)
n.subj <- length(list.subj)

save <- FALSE
```

## Functions

### Matrix to df

```{r}

matrix_to_df2 <- function(array, row.name, col.name, val.name) {
  array %>% 
    as_tibble() %>%
    rownames_to_column(row.name) %>%
    pivot_longer(-row.name, names_to = col.name, values_to = val.name) %>% 
    mutate("{col.name}" := str_remove(!!sym(col.name), "V")) %>% 
    mutate_all(as.numeric) %>% 
    return
}

# !!! USE as.data.frame.table() instead
```

### Batch data loading

```{r}
load_loop_subj <- function(folder, condition, group.mean = T, diag = F) {
  array.scores <- array(dim = c(141,141,n.subj))
  i <- 1
  for (s in list.subj) {
    tmp <- os$path$join(path.root, s, folder,
                        paste0("cv_", condition, "_scores.npy"))
    
    # Proceed to next subject if file doesn't exist
    if (!os$path$isfile(tmp)) {next}
    
    # Load data otherwise
    tmp <- np$load(tmp)
    
    # Average across CV folds if present
    if (length(dim(tmp)) == 3) {
      tmp <- tmp %>% apply(c(2,3), mean) # average across CV folds
    }
      
    array.scores[,,i] <- tmp
    i <- i+1
  }
  
  # Return a dataframe
  # --- average across participants if requested (default)
  if (group.mean) {
    df.out <- array.scores %>% 
      apply(c(1,2), mean) %>%
      matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy")
  # --- or participant-level data, with a subject identifier column
  } else {
    if (diag) {
      df.out <- tibble()
      for (i in 1:n.subj) {
        df.out %<>% bind_rows(
          array.scores[,,i] %>%
            matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") %>%
            filter(t_train == t_test) %>% mutate(id = list.subj[[i]])
        )
      }
    }
  }
  
  # Crop subject-level data for cluster analysis
  # array.scores <- array.scores[70:nrow(array.scores),,]
  return(list(array.scores, df.out))
}
```

### Correlations

```{r}

## Correlation function between two vectors
correlations_vecs <- function(slice, vec) {
  cor(as.vector(slice), vec)
}

# Bind time-generalization matrices from different entropic conditions into a single 3D array
correlations_extract3D <- function(data, idx.lines, idx.subj) {
  arr.tmp <- data[[idx.lines[1],"array"]][[1]][,,idx.subj]
  for (i in 2:length(idx.lines)) {
    arr.tmp <- abind(arr.tmp, data[[idx.lines[i],"array"]][[1]][,,idx.subj], along = 3)
  }
  return(arr.tmp)
}


# Replace NAs by 0 and extreme values by +/- .99
correlations_fixval <- function(arr.corr) {
  arr.corr[is.na(arr.corr)] <- 0
  arr.corr[arr.corr == 1] <- .99
  arr.corr[arr.corr == -1] <- -.99
  return(arr.corr)
}
```

### Cluster permutation stats

```{r}
get_signif_clust2d <- function(X, n_permutations = 2**12, n_jobs = -1) {
  # run permutaiton tests
  mne$stats$spatio_temporal_cluster_1samp_test(X,
                                               n_permutations = n_permutations,
                                               n_jobs = as.integer(n_jobs),
                                               out_type = "mask",
                                               verbose = FALSE) -> tmp
  names(tmp) <- c("t_obs","clusters","cluster_pv","H0")
  
  # Extract clusters: the final output is a 0/1 matrix, 1 indicating belonging to a significant cluster 
  # --- get ids of significant clusters
  idx.signif <- which(tmp$cluster_pv < .05) 
  # --- aggregate clusters
  signif <- array(0, dim = dim(tmp$t_obs)) 
  for (i in idx.signif) {
    signif <- signif + tmp$clusters[[i]]
  }
  
  return(1*(signif > 0))
}


# Loop through multiple conditions, stored in a dataframe where each row contains a 3D array in an "array" column
# Other columns are appended to the output as descriptors of the condition
cluster_loop_cond <- function(df, H0 = 0, n_permutations = 2**12, n_jobs = -1) {
  # Initialize significant clusters dataframe
  df.clusters <- tibble()
  # Loop through all conditions
  for (i in 1:nrow(df)) {
    
    # Extract array of subject-level time-generalized accuracy
    X <- df[[i,"array"]][[1]] %>% 
      # --- reshape to how MNE expects it
      np$moveaxis(as.integer(2), as.integer(0)) 
  
    df.clusters %<>% bind_rows(
      get_signif_clust2d(X-H0, n_jobs = n_jobs, n_permutations = n_permutations) %>% 
        matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "signif") %>% 
        bind_cols(select(df,-array)[i,])
    )
  }
  
  return(df.clusters)
}
```

### Difference original-reordered

```{r}

calculate_diff <- function(df, f.map, values_to) {
  df %>% 
    mutate(manip = case_match(manip, "" ~ "original", "_reord" ~ "reordered")) %>% 
    pivot_wider(names_from = manip, values_from = values_to) %>% 
    mutate(diff = f.map(original, reordered, .f=\(x,y){x-y})) %>% 
    pivot_longer(cols = c(original, reordered, diff), names_to = "manip", values_to = values_to)
}
```

### Base plot

```{r}
plot.base <- function(df.plot,
                      z = "accuracy",
                      contour = TRUE,
                      col.contour = col.clusters,
                      col.pal = rev(pals::brewer.rdbu(10)),
                      z.breaks = acc.breaks.base,
                      z.labels = acc.labels.base,
                      legend.position = "bottom") {
  
  # Onset lines
  lines.v.pos <- 330*seq(round(min(df.plot$t_test)/333), round(max(df.plot$t_test)/333), 1)
  lines.v.pos <- lines.v.pos[lines.v.pos!=0]
  lines.h.pos <- 330*seq(round(min(df.plot$t_train)/333), round(max(df.plot$t_train)/333), 1)
  lines.h.pos <- lines.h.pos[lines.h.pos!=0]

  # Plot
  g <- df.plot %>% 
    ggplot(aes(x = t_test, y = t_train)) +
    # --- heatmap
    geom_tile(aes_string(fill = z)) +
    # --- sounds onsets
    geom_vline(xintercept = lines.v.pos, linetype = 2, color = col.lines) +
    geom_hline(yintercept = lines.h.pos, linetype = 2, color = col.lines) +
    geom_vline(xintercept = 0, color = col.lines) +
    geom_hline(yintercept = 0, color = col.lines) +
    
    scale_x_continuous(breaks = scales::pretty_breaks(12),
                       expand = c(0,0)) +
    scale_y_continuous(breaks = scales::pretty_breaks(4),
                       expand = c(0,0)) +
    scale_fill_stepsn(colors = col.pal,
                      breaks = z.breaks,
                      labels = z.labels,
                      limits = c(min(z.breaks), max(z.breaks)),
                      oob = scales::squish) +
    
    labs(x = "Test time (ms)", y = "Train time (ms)") +
  
    coord_equal(clip = "off") +
    
    theme(# Text size
          plot.title = element_text(size = 12, hjust = 0.5, face = "bold"),
          plot.subtitle = element_text(size = 9, hjust = 0.5),
          axis.title = element_text(size = 9),
          legend.title = element_text(size = 9),
          strip.text = element_text(size = 9),
          axis.text = element_text(size = 5),
          legend.text = element_text(size = 5.5),
          # Time ticks
          axis.ticks = element_line(color = "black"),
          axis.ticks.length = unit(0.1, "cm"),
          # Legend
          legend.position = legend.position,
          legend.box.margin = margin(0,0,0,0),
          legend.box.spacing = unit(0, "pt"),
          # no grid
          panel.grid = element_blank(),
          # don't clip facet titles
          strip.clip = "off")
  
  if (legend.position %in% c("bottom","top")) {
    g <- g + 
      guides(fill = guide_colorbar(barwidth = 0.5*length(z.breaks-1), barheight = 0.5,
                                   ticks = F, title.vjust = 1))
  } else {
    g <- g + 
      guides(fill = guide_colorbar(barheight = 0.5*length(z.breaks-1), barwidth = 0.5,
                                   ticks = F, title.vjust = 1))
  }
  
  # --- significant clusters
  if (contour) {
    g <- g +
      geom_contour(aes(z = signif), size = 0.1, color = col.contour)
  }
  
  return(g)
}
```

## Parameters

### Transition matrices

From @demarchi2019

```{r}

mat.T <- list(RD = matrix(rep(.25, 16), ncol = 4, byrow = T),
              MM = matrix(), MP = matrix(), OR = matrix())

mat.T$MM <- matrix(c(c(.25,0,.37,.38),
                     c(.38,.25,0,.37),
                     c(.37,.38,.25,0),
                     c(0,.37,.38,.25)),
                   ncol = 4, byrow = T)

mat.T$MP <- matrix(c(c(.25,0,.15,.60),
                     c(.60,.25,0,.15),
                     c(.15,.60,.25,0),
                     c(0,.15,.60,.25)),
                   ncol = 4, byrow = T)

mat.T$OR <- matrix(c(c(.25,0,0,.75),
                     c(.75,.25,0,0),
                     c(0,.75,.25,0),
                     c(0,0,.75,.25)),
                   ncol = 4, byrow = T)

covCT <- function(mat.C, mat.T) {
  covar <- 0
  for (i in 1:dim(mat.C)[1]) {
    covar <- covar + mean((mat.C[i,]-mean(mat.C[i,]))*(mat.T[i,]-mean(mat.T[i,])))
  }
  return(covar)
}
```

### Plotting

```{r}
# Temporal resolution in ms (1000 / sampling frequency)
dt <- 10

# Colors
col.pal.base <- rev(pals::brewer.rdbu(10))
col.pal.diff <- rev(pals::brewer.brbg(10))
col.pal.corr <- pals::ocean.curl(100)
col.lines <- "grey40"
col.clusters <- "grey10"

# Breaks & Labels
# --- function
format_labels_acc <- function(labels) {
  labels[seq(2,length(labels),2)] <- ""
  labels <- str_replace(labels, "0.", ".")
}
# --- base
acc.breaks.base <- seq(.21,.29, .005)
acc.labels.base <- format_labels_acc(acc.breaks.base)
# --- diff
acc.breaks.diff <- seq(-.02,.02, .005)
acc.labels.diff <- format_labels_acc(acc.breaks.diff)
# --- correlations
corr.breaks <- seq(-1,1,.2)
corr.labels <- str_replace(corr.breaks, "0.", ".")

# GGPLOT theme
theme_update(plot.tag.position = c(0, 1),
             plot.tag = element_text(size = 14, hjust = 0, vjust = 1, face = "bold"))
```

# Figures

## METHODS

### Pitches

```{r}
#| fig-width: 1
#| fig-height: 2
#| output: false
df.plot.pitch <- tibble(pitch = c(200,430,928,2000))

df.plot.pitch %>% 
  ggplot(aes(x = 1, y = pitch, color = (pitch))) +
  geom_point(size = 4, show.legend = F) +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(name = "Pitch (Hz)",
                     breaks = df.plot.pitch$pitch) +
  scale_color_viridis_c(name = "Pitch (Hz)",
                        breaks = (df.plot.pitch$pitch),
                        trans = "log") +
  coord_cartesian(clip = "off") +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        panel.grid = element_blank(),
        panel.grid.major.y = element_line()) -> g.pitch

g.pitch
```

```{r}
#| eval: false
#| fig-width: 1
#| fig-height: 2
df.plot.pitch <- tibble(pitch = c(200,430,928,2000))

df.plot.pitch %>% 
  ggplot(aes(x = 1, y = pitch, color = (pitch))) +
  geom_point(size = 6) +
  scale_x_continuous(expand = c(0,0)) +
  scale_color_viridis_c(name = "Pitch (Hz)",
                        breaks = (df.plot.pitch$pitch),
                        trans = "log") +
  guides(color = guide_colorbar(title.hjust = 1,
                                label.position = "left",
                                label.vjust = c(0,0.5,0.5,1),
                                barwidth = 0.5, barheight = 8)) +
  coord_trans(y = scales::log_trans(),
              ylim = c(200/2.15, 2000*2.15),
              clip = "off") +
  theme_void() +
  theme(legend.position = "left",
        legend.box.margin = margin(b = 15, r=-20)) -> g.pitch2

g.pitch2

```

### Transition matrices

```{r}
#| output: false

# Convert & combine transition matrices into a dataframe
df.plot <- tibble()
for (condition in c("RD","MM","MP","OR")) {
  df.plot %<>% bind_rows(
    mat.T[[condition]] %>% 
      matrix_to_df2(row.name = "from", col.name = "to", val.name = "p") %>% 
      mutate(condition = condition)
  )  
}
df.plot %<>%
  mutate(condition = factor(condition, names(mat.T)))

df.plot.pitch <- bind_rows(tibble(x = 0.1, y = 1:4, pitch = 1:4),
                           tibble(y = 0.1, x = 1:4, pitch = 1:4))
# Plot
df.plot %>% 
  ggplot(aes(x = to, y = from)) +
  facet_wrap(~ condition, nrow = 1, strip.position = "bottom") +
  # --- heatmap
  geom_tile(aes(fill = p)) +
  # --- display percentages
  geom_text(data = . %>% filter(p<=.25),
            aes(label = paste0(100*p,"%")),
            color = "black", size = 2) +
  geom_text(data = . %>% filter(p>.25),
            aes(label = paste0(100*p,"%")),
            color = "white", size = 2) +
  # --- display color-coded pitch in axes
  geom_point(data = df.plot.pitch,
             aes(x, y, color = pitch), size = 4, show.legend = FALSE) +
  geom_text(data = df.plot.pitch,
             aes(x, y, label = pitch), color = "white", size = 2, show.legend = FALSE) +
  
  scale_color_viridis_c() +
  scale_x_continuous(name = "to\n", position = "top") +
  scale_y_reverse(name = "from\n") +
  scale_fill_gradient(name = "transition probability",
                      low = "white", high = "black",
                      labels = ~str_replace(., "^0.","."),
                      limits = c(0,1)) +
  guides(fill = guide_colorbar(barheight = 0.5,
                               ticks = F, title.vjust = 1)) +
  coord_equal(xlim = c(0.5,4.5), ylim = rev(c(0.5,4.5)),
              expand = F, clip = "off") +
  theme(legend.position = "bottom",
        legend.box.margin = margin(t = -20),
        # text size
        axis.title = element_text(size = 9),
        legend.title = element_text(size = 9),
        strip.text = element_text(size = 12),
        # remove axis text
        axis.text = element_blank(),
        # Positions & margins
        axis.title.x = element_text(hjust = 0.08),
        panel.spacing.x = unit(0.8,"cm")) -> g.transitions

g.transitions
```

### Reordering

```{r}
#| output: false

# Generate Markov sequences
n.samples <- 12
stims <- list(RD = c(), OR = c())
set.seed(128764) #20476, 99713
for (entropy in c("RD","OR")) {
  stims[[entropy]] <- vector("numeric", n.samples)
  stims[[entropy]][1] <- sample(1:4, 1)
  for (i in 2:n.samples) {
    stims[[entropy]][i] <- sample(1:4, 1, prob = mat.T[[entropy]][stims[[entropy]][i-1],])
  }
}

# Add global sequence indices, class-specific indices and offset according to pitch
df.plot <- stims %>% as.tibble() %>% 
  mutate(idx = as.double(1:n.samples)) %>% 
  pivot_longer(-idx, names_to = "entropy", values_to = "class") %>% 
  mutate(entropy = factor(entropy, levels = c("OR","RD"))) %>%
  group_by(entropy,class) %>% mutate(rank = rank(idx)) %>% 
  mutate(y = as.double(entropy) + class/16-10/64)

pitch.y <- sort(unique(df.plot$y))

# Plot
df.plot %>% 
  ggplot(aes(x = idx, y = y, color = class)) +
  
  # --- pitch lines
  geom_hline(yintercept = pitch.y, color = "grey90") +
  # --- pitch labels
  annotate(geom = "text", label = "pitch",
           x = 12.5, y = c(mean(head(pitch.y,4)), mean(tail(pitch.y,4))),
           hjust = 0.5, vjust = 1, size = 3, color = "grey50", angle = 90) +
  
  annotate(geom = "text", label = "low",
           x = 12.5, y = c(min(head(pitch.y,4)), min(tail(pitch.y,4))),
           hjust = 0.74, vjust = 2.5, size = 2.5, color = "grey50", angle = 90) +
  
  annotate(geom = "text", label = "high",
           x = 12.5, y = c(max(head(pitch.y,4)), max(tail(pitch.y,4))),
           hjust = 0.25, vjust = 2.5, size = 2.5, color = "grey50", angle = 90) +
  
  # --- reordering trajectories
  ggh4x::geom_pointpath(data = df.plot %>% arrange(desc(entropy)),
               aes(x = idx, y = y, group = interaction(class,rank)),
               mult = 0.4, color = "black", linewidth = 0.3,
               arrow = arrow(length=unit(.2, 'cm'))) +
  # --- stimuli
  geom_point(size = 4, show.legend = F) +
  # --- stimuli ranks
  geom_text(aes(label = rank), size = 2, color = "white") +
  
  scale_x_continuous(name = "sequence index", breaks = 1:n.samples) +
  scale_y_continuous(breaks = c(1,2), labels = c("OR","RD"), position = "left") +
  scale_color_viridis_c() +
  coord_cartesian(clip = "off") +
  
  theme(axis.title.y = element_blank(),
        axis.text.y = element_text(size = 12, color = "black"),
        axis.title.x = element_text(size = 9, color = "black"),
        panel.grid = element_blank(),
        panel.grid.major.x = element_line(color = "grey80", linewidth = 0.2)) -> g.reordering

g.reordering
```

### Prediction types

Presented vs. most likely

```{r, fig.width=2.5, fig.height=5.}
#| output: false

# Generate Markov sequences
n.samples <- 6
stims <- mat.T
set.seed(12871) #128764
for (entropy in names(stims)) {
  stims[[entropy]] <- vector("numeric", n.samples)
  stims[[entropy]][1] <- 4#sample(1:4, 1)
  for (i in 2:n.samples) {
    stims[[entropy]][i] <- sample(1:4, 1, prob = mat.T[[entropy]][stims[[entropy]][i-1],])
  }
}

# Add sequence index & predictions
df.plot <- stims %>% as.tibble() %>% 
  mutate(idx = as.double(1:n.samples)) %>% 
  pivot_longer(-idx, names_to = "entropy", values_to = "class") %>% 
  mutate(entropy = factor(entropy, levels = rev(names(stims)))) %>% 
  group_by(entropy) %>% mutate(actual = lead(class),
                               mostlikely = ifelse(class==1, 4, class-1)) %>% 
  pivot_longer(c(actual,mostlikely), names_to = "status", values_to = "class.pred")

# Plot
df.plot %>% 
  ggplot(aes(x = idx, y = class)) +
  facet_wrap(~ entropy, ncol = 1, strip.position = "right") +
  
  geom_segment(data = df.plot %>% filter(status == "mostlikely", idx != n.samples),
               aes(x = idx, xend = idx+1, y = class, yend = class.pred, linetype = as.factor(sign(class.pred-class))),
               arrow = arrow(type = "closed", length = unit(6,"pt")),
               color = "grey30", show.legend = F) +
  
  geom_point(aes(fill = class), size = 2.5, shape = 21, color = "white", show.legend = T) +
  
  geom_point(data = df.plot %>% filter(status == "mostlikely", idx != n.samples),
             aes(x = idx+1, y = class.pred, color = "grey30"),
             size = 2.5, shape = 1) +
  # geom_point(data = df.plot %>% filter(status == "mostlikely", idx != n.samples),
  #            aes(x = idx+1, y = class.pred), size = 2, shape = 8) +
  
  scale_x_continuous(name = "sequence index", breaks = 1:n.samples) +
  scale_y_continuous(name = "") +
  scale_color_identity(guide = "legend", name = "", labels = "most likely") +
  scale_fill_viridis_c(guide = "legend", name = "", labels = c("","","","actually presented")) +
  
  guides(linetype = F) +
  coord_cartesian(clip = "off") +
  expand_limits(x = c(0.9,6.1), y = c(0.3,4.7)) +
  # labs(caption = str_wrap("Colored points represent actual stimuli, grey arrows and open circles represent predictions from current stimulus.", width = 70)) +
  
  guides(color = guide_legend(order = 1, override.aes = list(color = "grey50")),
         fill = guide_legend(order = 2)) +
  theme(plot.caption = element_text(size = 6),
        axis.text.y = element_blank(),
        axis.title.x = element_text(size = 9, color = "black"),
        strip.text = element_text(size = 12),
        panel.spacing = unit(0.2,"cm"),
        panel.grid = element_blank(),
        panel.border = element_rect(fill=NA),
        legend.position = "top",
        legend.box = "vertical",
        legend.box.just = "left",
        legend.margin = margin(b = -10),
        legend.text = element_text(margin = margin(r = -12, l=-3,  unit = "pt"))
        ) -> g.mostlikely

g.mostlikely
```

### Assemble

```{r}
#| fig-width: 8
#| fig-height: 4.5
#| column: page
#| lightbox:
#|   group: r-graph

((g.pitch + labs(title = "")) +
    plot_spacer() +
    (g.transitions + labs(title = "Transition matrices")) +
    plot_layout(widths = c(0.5,0.2,15))) / (
wrap_elements(full = g.reordering + labs(title="Reordering of random data")) +
   plot_spacer() +
   (g.mostlikely + labs(title="Predictions")) +
  plot_layout(widths = c(1,0.05,1))
) + 
  plot_layout(heights = c(1.4,1)) +
  plot_annotation(tag_levels = "a") &
  
  theme(plot.title = element_text(size = 12),
        plot.title.position = "panel",
        plot.tag.position = c(0, 1),
        plot.tag = element_text(size = 14, hjust = 0, vjust = 1, face = "bold")) -> g

g

if (save) {
  g %>% ggsave(filename = "./figures/fig1.png", width = 8, height = 4.5, dpi = 300, device = ragg::agg_png)
}
```

**Figure 1.** Original experimental design and reanalyses. **(a)** Demarchi et al. (2019) presented four different pure sinusoidal tones, logarithmically spaced in pitch. **(b)** Four types of sequences of sounds were generated, each using a Markov chain characterized by a distinct transition matrix. The transition matrices were manipulated so that (i) probabilities of repetitions (diagonal elements) were the same across sounds and sequences, (ii) the identity of the most likely next sound was the same in all sequences, and (iii) the entropy of the generated sequences decreased from RD (random) to MM (midminus), to MP (midplus) to OR (ordered). **(c)** In our reanalysis, we created a new control dataset by reordering epochs from randomly sequences according to the sequence order of higher entropy conditions (here, OR). By construction, any above chance level decoding accuracy on this control dataset could only be attributed to sequence effects and not to brain representations. (d) Demarchi et al. (2019) decoded the sound that was actually presented to the participants (colored circles), which was not always the most likely one given the previous stimulus (asterisks); the lower the entropy, the more discrepancy between the two. In our reanalysis, we decoded both types of prediction.

## ORIGINAL & REORDERED

### Load

#### Stimulus data

```{r}
#| cache: true

tic()

# Load subject-level data and derive grand average
df.stim.mean <- tibble()
df.stim.subj <- tibble()
for (manip in c("","_reord")) { 
  
  for (direction in c("rd_to_rd", "rd_to_mm", "rd_to_mp", "rd_to_or")) {
    tmp <- load_loop_subj(folder = "reorder_random",
                          condition = paste0(direction, manip))
    
    df.stim.mean %<>% bind_rows(tmp[[2]] %>% mutate(manip = manip, direction = direction))
    df.stim.subj %<>% bind_rows(tibble(manip = manip, direction = direction, array = list(tmp[[1]])))
  }
}

df.stim.mean %<>% mutate(stim = "sounds")
df.stim.subj %<>% mutate(stim = "sounds") %>% mutate(array = map(array, .f=\(x){x-0.25}))

toc() # ~40s
```

#### Omission data

```{r}
#| cache: true

tic()

df.omit.mean <- tibble()
df.omit.subj <- tibble()
for (manip in c("","_reord")) { 
  
  for (direction in c("rd_to_rd", "rd_to_mm", "rd_to_mp", "rd_to_or")) {
      
    tmp <- load_loop_subj(folder = "reorder_random_omission",
                          condition = paste0(direction, manip))
    
    df.omit.mean %<>% bind_rows(tmp[[2]] %>% mutate(manip = manip, direction = direction))
    df.omit.subj %<>% bind_rows(tibble(manip = manip, direction = direction, array = list(tmp[[1]])))
  }
}

df.omit.mean %<>% mutate(stim = "omissions")
df.omit.subj %<>% mutate(stim = "omissions") %>% mutate(array = map(array, .f=\(x){x-0.25}))

toc() # ~ 2s
```

### Correlations with entropy

```{r}

## Prepare input data
df.tmp <- bind_rows(df.stim.subj, df.omit.subj) %>% 
  calculate_diff(f.map = map2, values_to = "array") %>%
  mutate(regularity = str_remove(direction, "rd_to_"),
         regularity = factor(regularity, levels = c("rd","mm","mp","or"))) %>% 
  select(-direction) %>% 
  arrange(as.numeric(regularity))
df.tmp


tic()
df.corr.mean <- tibble()
df.corr.subj <- tibble() 
## Loop through condition "manip" and stimulus type "stim
for (mm in c("original","reordered","diff")) { 
  print(mm)
  for (ss in c("sounds", "omissions")) {
    print(ss)
    
    # --- Loop through subjects to derive a 3D array of participant-level time-generalized correlations with entropy, from a 3D array of participant-level accuracy matrix
    for (idx.subj in 1:n.subj) {
      
      # --- bind time-generalization matrices for the 3 non-random conditions into a single 3D array
      # (add accuracy data from the random condition if we are processing sounds)
      if (ss == "sounds") {
        idx.lines = 1:4
      } else if (ss == "omissions") {
        idx.lines = 2:4
      }
      arr.tmp <- correlations_extract3D(data = filter(df.tmp, manip == mm, stim == ss),
                                        idx.lines = idx.lines, idx.subj)
      
      # --- calculate correlation with entropy level coded as 0,1,2(,3), obtaining a 2D array
      if (ss == "sounds") {
        arr.corr.tmp <- apply(arr.tmp, 1:2, correlations_vecs, vec = 0:3)
      } else if (ss == "omissions") {
        arr.corr.tmp <- apply(arr.tmp, 1:2, correlations_vecs, vec = 1:3)
      }
      
      # --- append to already processed subjects in a 3D array
      if (idx.subj == 1) {
        arr.corr <- arr.corr.tmp
      } else {
        arr.corr %<>% abind(arr.corr.tmp, along = 3)
      }
    }
    
    # Replace NAs by 0 and extreme values by +/- .99
    arr.corr <- correlations_fixval(arr.corr)
    
    # --- store participant-level results in a dataframe
    df.corr.subj %<>% bind_rows(tibble(manip = mm, stim = ss, array = list(arr.corr)))
    
    # --- calculate groupe average and store in a dataframe
    df.corr.mean %<>% bind_rows(
      arr.corr %>% 
        atanh %>%  # apply Fisher's transformation
        apply(c(1,2), mean) %>% # average across participants
        tanh %>% # convert back to correlation coefficients  
        matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "r") %>% 
        mutate(manip = mm, stim = ss)
    )
  }
}
toc() # ~2min

```

### Clusters stats

#### Accuracy

```{r}
#| cache: true

tic()

# Cluster analysis
df.clusters.0 <- bind_rows(df.stim.subj, df.omit.subj) %>% 
  calculate_diff(f.map = map2, values_to = "array") %>% 
  cluster_loop_cond(n_permutations = 10000)

# Aggregate all data and clean
df.plot.0 <- bind_rows(df.stim.mean, df.omit.mean) %>%
  calculate_diff(f.map = map2_dbl, values_to = "accuracy") %>% 
  # --- append cluster significance
  left_join(df.clusters.0) %>%
  mutate(manip = (recode_factor(manip, original = "ORIGINAL", reordered = "REORDERED",
                                diff = "ORIGINAL – REORDERED"))) %>% 
  mutate(direction = toupper(sub("rd_to_", "", direction)),
         direction = factor(direction, levels = rev(c("RD","MM","MP","OR")))) %>%
  # --- convert indices to time
  mutate(across(starts_with("t_"), ~(dt*(.-1)-700))) %>%
  # --- crop time
  filter(t_train>=0, (t_train-333) < dt)

toc() # 20 minutes
```

#### Correlations

```{r}

tic()
df.clusters.corr <- df.corr.subj %>% 
  cluster_loop_cond(n_permutations = 10000)
toc() # ~ 10 min

# --- append cluster significance
df.plot.0.corr <- df.corr.mean %>% 
  left_join(df.clusters.corr) %>%
  mutate(manip = (recode_factor(manip, original = "ORIGINAL", reordered = "REORDERED",
                                diff = "ORIGINAL – REORDERED"))) %>% 
  #mutate(direction = toupper(sub("rd_to_", "", direction)),
  #       direction = factor(direction, levels = rev(c("RD","MM","MP","OR")))) %>%
  # --- convert indices to time
  mutate(across(starts_with("t_"), ~(dt*(.-1)-700))) %>%
  # --- crop time
  filter(t_train>=0, (t_train-333) < dt)

df.plot.0.corr

```



### Plot v1

```{r}
#| fig-width: 8
#| fig-height: 7
#| column: page
#| lightbox:
#|   group: r-graph

g.base <- list(sound = c(), omission = c())
g.diff <- list(sound = c(), omission = c())

for (s in c("sounds","omissions")) {
  # ORIGINAL & REORDERED
  df.plot.0 %>% 
    filter(stim == s, manip != "ORIGINAL – REORDERED") %>% 
    mutate(manip = paste0("Test data: ", manip)) %>% 
    plot.base(col.pal = col.pal.base,
              z.breaks = acc.breaks.base,
              z.labels = acc.labels.base) +
    facet_grid(direction ~ manip) +
    labs(title = paste0(toupper(s), ", decoding presented")) -> g.base[[s]]
  
  # DIFFERENCE
  df.plot.0 %>%
    filter(stim == s, manip == "ORIGINAL – REORDERED") %>% 
    plot.base(col.pal = col.pal.diff,
              z.breaks = acc.breaks.diff,
              z.labels = acc.labels.diff) +
    facet_grid(direction ~ manip) +
    labs(title = toupper(s)) +
    theme(axis.title.y = element_blank()) -> g.diff[[s]]
}

(g.base[["sounds"]] + g.diff[["sounds"]] + plot_layout(widths = c(2, 1))) /
  (g.base[["omissions"]] + g.diff[["omissions"]] + plot_layout(widths = c(2, 1))) +
  plot_annotation(tag_levels = c("a","b","c","d")) &
  theme(plot.tag.position = c(0, 1)) -> g

g

if (save) {
  g %>% ggsave(filename = "./figures/fig2.png", width = 8, height = 7.5, dpi = 300, device = ragg::agg_png)
}
```

**Figure 2.** Time-generalization decoding of sounds presented in structured sequences with a classifier trained on random sound sequences. **(a, left)** replicates Demarchi et al. approach (figure 3a in the original publication) where above 25% chance level decoding appears possible several hundreds milliseconds before and after the stimulus. The design of our figure is different in two important aspects. First, we set up the color scale so as to reduce the saturation present in the original figure. Yet, in both the original and replicated analyses, the pre-stimulus decoding peaks in the highly regular condition (OR) at -230ms (i.e. approximately 100ms after the onset of the preceding sound) and exceeds the 25% chance level by less than 1 percentage point. Both analyses also reveal late post-stimulus decoding peaking slightly before 500ms after stimulus onset for train times around 100ms. Second, we have extended the testing time to cover the second stimulus before the target, which revealed below 25% chance level accuracy, suggesting that decoding performance was at least partly driven by statistical dependency between stimuli. **(a, right)** is the same analysis, carried out on random generated data re-ordered to mimic structured sequences (see Methods and fig. 1c). Pre-stimulus decoding is found again and **(b)** differentiation with the original results indicate that it is comparable in temporal pattern and magnitude. Residual pre-stimulus decoding is not statistically significant anymore, late post-stimulus decoding remains present. Note the negative diagonal during the decoded stimulus, which reflects the better tuning of the classifier to data coming from the random condition, as well as the positive upper diagonal during $S_{+1}$ which is due to cropping in reordered data. **(c,d)** Original and re-ordering analyses applied to omitted sounds (figure 3b in the original publication) lead to the same conclusions.

### Plot "Matters Arising"

#### Initialize
```{r}
g.base <- list(sound = c(), omission = c())
g.diff <- list(sound = c(), omission = c())

# Create ad hoc dataframes for onset' labels
df.labels.onset <- list(
  sounds = tibble(label = "sound onset",
                manip = factor(c("REPLICATION\n", "EMPIRICAL NULL\n",
                                 "REPLICATION – EMPIRICAL NULL\n")),
                direction = factor("OR", levels = names(stims))),
  omissions = tibble(label = "omission onset",
                manip = factor(c("REPLICATION\n", "EMPIRICAL NULL\n",
                                 "REPLICATION – EMPIRICAL NULL\n")),
                direction = factor("OR", levels = names(stims)))
)
  
# Function to add onset' labels to a plot
add_onset <- function(g, df.labels) {
  g <- g + geom_text(data = df.labels %>% filter(manip %in% unique(g$data$manip)),
                     aes(label = label, x = 0, y = 350),
                     hjust = 0, vjust = -0.5, size = 3, fontface = "italic")
  return(g)
}
```

#### Build accuracy plots

```{r}

for (s in c("sounds","omissions")) {
  # ORIGINAL & REORDERED
  df.plot.0 %>% 
    filter(stim == s, manip != "ORIGINAL – REORDERED") %>% 
    # mutate(manip = paste0("Test data: ", manip)) %>% 
    mutate(manip = recode_factor(manip, 
                                 ORIGINAL = "REPLICATION\n", #  (original dataset)\n
                                 REORDERED = "EMPIRICAL NULL\n")) %>%  # (reordered RD)\n
    plot.base(col.pal = col.pal.base,
              z.breaks = acc.breaks.base,
              z.labels = acc.labels.base) +
    facet_grid(direction ~ manip) -> g
  
  g.base[["acc"]][[s]] <- g %>% add_onset(df.labels.onset[[s]])
    # scale_x_continuous(breaks = seq(-600,600,100)) +
    # labs(title = paste0("Trials: ", toupper(s), " / Decoded: PRESENTED stimulus")) -> 
  
  # DIFFERENCE
  g.diff[["acc"]][[s]] <- df.plot.0 %>%
    filter(stim == s, manip == "ORIGINAL – REORDERED") %>%
    mutate(manip = recode_factor(manip,
                                 `ORIGINAL – REORDERED` = "REPLICATION – EMPIRICAL NULL\n")) %>%
    plot.base(col.pal = col.pal.diff,
              z.breaks = acc.breaks.diff,
              z.labels = acc.labels.diff) +
    facet_grid(direction ~ manip) +
    # scale_x_continuous(breaks = seq(-600,600,100)) +
    # labs(title = paste0("Trials: ", toupper(s))) +
    theme(axis.title.y = element_blank()) -> g
  
  g.diff[["acc"]][[s]] <- g %>% add_onset(df.labels.onset[[s]])
}

# Assemble Figure 1c
g.fig1.1.acc <- (
  g.base[["acc"]][["sounds"]] + 
    (g.diff[["acc"]][["sounds"]] + plot_layout(tag_level = "new")) +
    plot_layout(widths = c(2, 1)) &
    theme(strip.text.x = element_text(face = "bold"))
)

g.fig1.1.acc

# Assemble Supplementary Figure 1a
g.supfig1.acc <- (
  g.base[["acc"]][["omissions"]] + 
    (g.diff[["acc"]][["omissions"]] + plot_layout(tag_level = "new")) +
    plot_layout(widths = c(2, 1)) &
    theme(strip.text.x = element_text(face = "bold"))
)

g.supfig1.acc

```

#### Build correlations plots

```{r}

for (s in c("sounds", "omissions")) {
  # ORIGINAL & REORDERED
  df.plot.0.corr %>% 
    filter(stim == s, manip != "ORIGINAL – REORDERED") %>% 
    # mutate(manip = paste0("Test data: ", manip)) %>% 
    mutate(manip = recode_factor(manip, 
                                 ORIGINAL = "REPLICATION\n", #  (original dataset)\n
                                 REORDERED = "EMPIRICAL NULL\n")) %>%  # (reordered RD)\n
    mutate(direction = "") %>% 
    plot.base(col.pal = col.pal.corr,
              z = "r",
              z.breaks = corr.breaks,
              z.labels = corr.labels) +
    # scale_x_continuous(breaks = seq(-600,600,100)) +
    labs(fill = "Correlation") +
    facet_grid(direction ~ manip) -> g
  
  g.base[["corr"]][[s]] <- g %>% add_onset(df.labels.onset[[s]] %>% mutate(direction = ""))
  
  # DIFFERENCE
  df.plot.0.corr %>%
    filter(stim == s, manip == "ORIGINAL – REORDERED") %>% 
    mutate(manip = recode_factor(manip,
                                 `ORIGINAL – REORDERED` = "REPLICATION – EMPIRICAL NULL\n")) %>% 
    mutate(direction = "") %>% 
    plot.base(col.pal = col.pal.corr,
              z = "r",
              z.breaks = corr.breaks,
              z.labels = corr.labels) +
    facet_grid(. ~ manip) +
    # scale_x_continuous(breaks = seq(-600,600,100)) +
    labs(fill = "Correlation") +
    # labs(title = paste0("Trials: ", toupper(s))) +
    theme(axis.title.y = element_blank()) -> g
  
  g.diff[["corr"]][[s]] <- g %>% add_onset(df.labels.onset[[s]] %>% mutate(direction = ""))
}

# Assemble Figure 1d
g.fig1.1.corr <- (
  g.base[["corr"]][["sounds"]] + 
    (g.diff[["corr"]][["sounds"]] + plot_layout(tag_level = "new")) + 
    plot_layout(widths = c(2, 1)) &
    theme(strip.text = element_blank())
)

g.fig1.1.corr

# Assemble Supplementary Figure 1a
g.supfig1.corr <- (
  g.base[["corr"]][["omissions"]] + 
    (g.diff[["corr"]][["omissions"]] + plot_layout(tag_level = "new")) +
    plot_layout(widths = c(2, 1)) &
    theme(strip.text.x = element_text(face = "bold"))
)

g.supfig1.corr
```

#### Combine into figure 1

```{r, fig.width = 7, fig.height = 11.5}

((g.transitions + theme(panel.spacing.x = unit(5,"mm"))) + free(g.reordering) + plot_layout(widths = c(1.5, 1))) / 
  ((g.fig1.1.acc / g.fig1.1.corr & theme(axis.text.x = element_text(angle = 45, hjust = 1))) + 
     plot_layout(heights = c(4, 1))) / 
  ((g.fig1.2.acc / g.fig1.2.corr & theme(axis.text.x = element_text(angle = 45, hjust = 1))) + 
     plot_layout(heights = c(4, 1))) +
  plot_layout(heights = c(1, 4, 4)) +
  plot_annotation(tag_levels = "a") -> g

g

if (save) {
  g %>% ggsave(filename = "./figures/fig1_MattersArising2.png", width = 7, height = 11.5, dpi = 300, device = ragg::agg_png)
}
```


#### Combine into supp figure 1 (omissions)

```{r, fig.width = 7, fig.height = 5.5}

((g.supfig1.acc / g.supfig1.corr & theme(axis.text.x = element_text(angle = 45, hjust = 1))) + 
   plot_layout(heights = c(4, 1))) +
  plot_annotation(tag_levels = "a") -> g

g

if (save) {
  g %>% ggsave(filename = "./figures/supfig1_MattersArising.png", width = 7, height = 5.5, dpi = 300, device = ragg::agg_png)
}
```


### \[Sandbox analyses\]

```{r}

## Explore diagonal elements of the time-generalization matrix, subject-wise

df.tmp <- df.stim.subj %>% 
  calculate_diff(f.map = map2, values_to = "array") %>% 
  filter(manip == "diff")
df.plot.0.diag <- tibble()
for (k in 1:nrow(df.tmp)) {
  d <- df.tmp$direction[k]
  for (i in 1:n.subj) {
    df.plot.0.diag %<>% bind_rows(
      df.tmp[[k,"array"]][[1]][,,i] %>% 
        matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") %>% 
        filter(t_train == t_test) %>% 
        mutate(direction = d, id = list.subj[[i]])
    )
  }
}


df.plot <- df.plot.0.diag %>% 
  filter(t_train >= 70, t_train <= 103) %>% 
  mutate(t_train = dt*(t_train-70))
  
df.plot %>% 
  ggplot(aes(x = t_train, y = accuracy, color = direction)) +
  facet_wrap(~ id, ncol = 6) +
  geom_line() 

```

```{r}

## Non-linear modeling of diagonal elements of the time-generalized matrix

df.model <- df.plot %>%
  mutate(across(c(id,direction), as.factor)) %>% 
  mutate(start.event = (t_train == 0)) %>% 
  mutate(direction = ordered(relevel(direction, ref="rd_to_rd")))

contrasts(df.model$direction) <- "contr.treatment"

library(mgcv)
library(gratia)
library(itsadug)
m.fx_1 <- gam(accuracy ~ s(t_train),
              data = df.model)
summary(m.fx_1)
plot(m.fx_1)

m.fx_dir <- gam(accuracy ~ direction + s(t_train, by=direction),
                data = df.model)
summary(m.fx_dir)
gratia::draw(m.fx_dir, parametric = TRUE, grouped_by = T, rug = F, ncol = 3, scales = "fixed")

m.fx_1.rd_1 <- gam(accuracy ~ s(t_train) + s(id, bs="re"),
                   data = df.model)
summary(m.fx_1.rd_1)
gratia::draw(m.fx_1.rd_1, parametric = TRUE, grouped_by = T, rug = F, ncol = 3, scales = "fixed")

m.fx_dir.rd_1 <- gam(accuracy ~ direction + s(t_train, by=direction) + s(id, bs="re"),
                     data = df.model)
summary(m.fx_dir.rd_1)
gratia::draw(m.fx_dir.rd_1, parametric = TRUE, grouped_by = T, rug = F, ncol = 3, scales = "fixed")

m.fx_1.rd_t <- gam(accuracy ~ s(t_train) + s(t_train, id, bs="fs", m=1),
          data = df.model)
summary(m.fx_1.rd_t)
gratia::draw(m.fx_1.rd_t, parametric = TRUE, grouped_by = T, rug = F, ncol = 3, scales = "fixed")

m.fx_dir.rd_t <- gam(accuracy ~ direction + s(t_train, by=direction) + s(t_train, id, bs="fs", m=1),
          data = df.model) #, method = "ML"
summary(m.fx_dir.rd_t)
gratia::draw(m.fx_dir.rd_t, parametric = TRUE, grouped_by = T, rug = F, ncol = 3, scales = "fixed")
plot(m.fx_dir.rd_t)

m.fx_dir.rd_t.ar.6 <- gam(accuracy ~ direction + s(t_train, by=direction) + s(t_train, id, bs="fs", m=1),
          data = df.model, AR.start = df.model$start.event, rho=0.6)#, method = "ML"
summary(m.fx_dir.rd_t.ar.6)
gratia::draw(m.fx_dir.rd_t.ar.6, parametric = TRUE, grouped_by = T, rug = F, ncol = 3, scales = "fixed")

acf_plot(resid(m.fx_1))
acf_plot(resid(m.fx_dir))
acf_plot(resid(m.fx_1.rd_1))
acf_plot(resid(m.fx_dir.rd_1))
acf_plot(resid(m.fx_1.rd_t))
acf_plot(resid(m.fx_dir.rd_t))
acf_plot(resid(m.fx_dir.rd_t.ar.6))

```

## THEORETICAL

### Load confusion matrices & calculate

```{r}
#| cache: true

tic()
null_accuracy <- function(mat.confusion, mat.transition) {
  # Calculate accuracy under the null hypothesis from the transition and confusion matrices mat.T and mat.C
  # The 3/4 factor is used to compensate the unbiased estimator used in cov() by default (see ?cov)
  return(0.25 + sum(diag(3/4*cov(t(mat.transition), t(mat.confusion)))))
}

df.maths.subj <- tibble()
df.maths.mean <- tibble()
for (entropy in c("RD","MM","MP","OR")) {

  array.scores <- array(0.25, dim = c(34,136,n.subj))
  # tmp.all <- array(dim = c(34,34,4,4,n.subj))
  i <- 1
  for (s in list.subj) {
    
    # --- load the confusion matrix
    tmp.file <- os$path$join(path.root, s, "reorder_random", "rd_to_rd_confmats.npz") %>%
      np$load()
    
    # --- crop around S0 (decoded stimulus)
    mat.C <- tmp.file$f[["arr_0"]][,71:104,71:104,,] %>%
      apply(c(2,3,4,5), mean)
    
    # tmp.file$close()
    
    # # --- append to other subjects
    # tmp.all[,,,,i] <- mat.C
    
    # NOTE: because the transition matrix is the same for all subjects, theoretical accuracy can be calculated from the group average of the confusion matrix (faster)
    # --- calculate theoretical accuracy
    #   --- for S-2
    array.scores[,1:34,i] <- mat.C %>%
      apply(c(1,2), null_accuracy, mat.transition = mat.T[[entropy]]%^%2)
    #   --- for S-1
    array.scores[,35:68,i] <- mat.C %>%
      apply(c(1,2), null_accuracy, mat.transition = mat.T[[entropy]]%^%1)
    #   --- for S
    array.scores[,69:102,i] <- mat.C %>%
      apply(c(1,2), \(x)mean(diag(x)))
    #   --- for S+1
    array.scores[,103:136,i] <- mat.C %>%
      apply(c(1,2), null_accuracy, mat.transition = t(mat.T[[entropy]]))
    i <- i+1
  }
  
  # Append to other entropies in dataframe
  # --- subject-level data
  df.maths.subj %<>% bind_rows(tibble(array = list(array.scores), entropy = entropy))
  # --- group-averaged data
  df.maths.mean %<>% bind_rows(array.scores %>% 
      apply(c(1,2), mean) %>%
      matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") %>% 
    mutate(entropy = entropy)
  )
}

toc() # ~ 1min
```

### [Deprecated: Calculate group-level theoretical accuracy]

```{r}

tic()

# Average across participants
mat.C.mean <- tmp.all %>% apply(c(1,2,3,4), mean)

df.maths.acc <- tibble()
for (entropy in c("RD","MM","MP","OR")) {
  df.maths.acc %<>%
    # Theoretical results for stimulus "S minus 2"
    bind_rows(mat.C.mean %>%
                apply(c(1,2), null_accuracy, mat.transition = mat.T[[entropy]]%^%2) %>%
                matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") %>% 
                mutate(entropy = entropy, stimulus = "S-2")
              ) %>% 
    # Theoretical results for stimulus "S minus 1"
    bind_rows(mat.C.mean %>%
                apply(c(1,2), null_accuracy, mat.transition = mat.T[[entropy]]%^%1) %>%
                matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") %>% 
                mutate(entropy = entropy, stimulus = "S-1")
              ) %>% 
    # Theoretical results for stimulus "S+1"
    bind_rows(mat.C.mean %>%
                apply(c(1,2), null_accuracy, mat.transition = t(mat.T[[entropy]])) %>%
                matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "accuracy") %>% 
                mutate(entropy = entropy, stimulus = "S+1")
              )
}

toc() # ~ 1s
```


### Correlations with entropy

```{r}

tic()

df.corr.maths.mean <- tibble()
df.corr.maths.subj <- tibble() 

for (mm in c("original","maths","diff")) { 
  # --- Loop through subjects to derive a 3D array of participant-level time-generalized correlations with entropy, from a 3D array of participant-level accuracy matrix
  for (idx.subj in 1:n.subj) {
    
    # --- bind time-generalization matrices for the 4 conditions into a single 3D array
    arr.tmp <- correlations_extract3D(data = df.maths.all %>% filter(manip == mm),
                                      idx.lines = 1:4, idx.subj)
    
    # --- calculate correlation with entropy level coded as 0,1,2,3, obtaining a 2D array
    arr.corr.tmp <- apply(arr.tmp, 1:2, correlations_vecs, vec = 0:3)
    
    # --- append to already processed subjects in a 3D array
    if (idx.subj == 1) {
      arr.corr <- arr.corr.tmp
    } else {
      arr.corr %<>% abind(arr.corr.tmp, along = 3)
    }
  }
  
  # Replace NAs by 0 and extreme values by +/- .99
  arr.corr <- correlations_fixval(arr.corr)
  
  # --- store participant-level results in a dataframe
  df.corr.maths.subj %<>% bind_rows(tibble(manip = mm, array = list(arr.corr)))
  
  # --- calculate group average and store in a dataframe
  df.corr.maths.mean %<>% bind_rows(
    arr.corr %>% 
      atanh %>%  # apply Fisher's transformation
      apply(c(1,2), mean) %>% # average across participants
      tanh %>% # convert back to correlation coefficients  
      matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "r") %>% 
      mutate(manip = mm)
  )
}

toc() # ~ 20s
```


### Clusters stats

#### Accuracy

```{r}
#| cache: true

tic()
df.clusters.maths <-
  # --- aggregate original, theoretical and difference between the 2
  bind_rows(df.stim.subj %>%
              # --- select original analysis
              filter(manip == "") %>% mutate(manip = "original") %>% 
              # --- crop to the same time-window than for theoretical analysis
              mutate(array = map(array, .f=\(x){x[71:104,3:138,]})) %>% 
              # mutate(array = list(array[[1]][71:104,3:138,])) %>% 
              mutate(entropy = toupper(str_replace(direction,"rd_to_",""))),
            df.maths %>%
              mutate(manip = "maths") %>% 
              mutate(array = map(array, .f=\(x){x-0.25}))) %>% 
  select(manip, entropy, array) %>% 
  pivot_wider(names_from = manip, values_from = "array") %>% 
  mutate(diff = map2(original, maths, .f=\(x,y){x-y})) %>% 
  pivot_longer(cols = c(original, maths, diff), names_to = "manip", values_to = "array") %>% 
  # --- cluster
  cluster_loop_cond(n_permutations = 10000)
toc() # ~ 2min

# Check with a quick plot
df.clusters.maths %>% 
ggplot(aes(x = t_test, y = t_train, fill = signif)) +
  facet_grid(entropy ~ manip) +
  geom_tile() +
  coord_equal()

```

#### Correlations

```{r}

tic()
df.clusters.corr.maths <- df.corr.maths.subj %>% 
  cluster_loop_cond(n_permutations = 10000)
toc() # ~ 10s

# Check with a quick plot
df.clusters.corr.maths %>% 
ggplot(aes(x = t_test, y = t_train, fill = signif)) +
  facet_grid(manip ~ .) +
  geom_tile() +
  coord_equal()

# --- append cluster significance
df.plot.maths.corr <- df.corr.maths.mean %>% 
  left_join(df.clusters.corr.maths) %>%
  mutate(manip = (recode_factor(manip, original = "ORIGINAL", maths = "THEORETICAL NULL",
                                diff = "ORIGINAL – THEORETICAL NULL"))) %>% 
  #mutate(direction = toupper(sub("rd_to_", "", direction)),
  #       direction = factor(direction, levels = rev(c("RD","MM","MP","OR")))) %>%
  # --- convert indices to time
  mutate(t_train = dt*(t_train-1) - 0,
         t_test = dt*(t_test-1) - 680) %>% 
    # --- crop time
  filter(t_train>=0, (t_train-333) < dt)

df.plot.maths.corr

```



### [Deprecated: Calculate diff with reordered]

```{r}

## Clean & prepare
df.plot.maths <- df.maths.all %>% 
  mutate(across(starts_with("t_"), ~dt*(.-1))) %>% 
  filter(t_test!=0) %>% mutate(t_test = t_test + 330*as.numeric(str_remove(stimulus,"S"))) %>%
  mutate(entropy = factor(entropy, levels = rev(names(mat.T))),
         stimulus = factor(stimulus, levels = c("S-2", "S-1", "S+1")))
  
## Append re-ordered data
df.plot.maths %<>% 
  mutate(manip = "THEORETICAL") %>% 
  bind_rows(df.plot.0 %>%
              rename(entropy = direction) %>%
              filter(manip == "REORDERED", stim == "sounds", entropy != "RD", t_train < 333,
                     (t_test > -666 & t_test<0) | (t_test > 333 & t_test < 666))
  ) %>% 
  select(starts_with("t_"), entropy, manip, accuracy)

## Calculate difference
df.plot.maths %<>%
    # mutate(manip = case_match(manip, "" ~ "original", "_reord" ~ "reordered")) %>%
    pivot_wider(names_from = manip, values_from = "accuracy") %>%
    mutate(diff = THEORETICAL - REORDERED) %>%
    pivot_longer(cols = c(THEORETICAL, REORDERED, diff), names_to = "manip", values_to = "accuracy")

## Cluster analysis of difference

```

### Plot v1

```{r}
#| fig-width: 8
#| fig-height: 4
#| column: page
#| lightbox:
#|   group: r-graph

## Plot
# THEORETICAL & REORDERED
df.plot.maths %>% 
  filter(manip != "diff") %>% 
  mutate(manip = factor(manip, levels = c("THEORETICAL","REORDERED"))) %>% 
  # mutate(manip = map_chr(manip, \(x){ifelse(x=="diff", "THEORETICAL – REORDERED", x)})) %>% 
  plot.base(col.pal = col.pal.base,
            z.breaks = acc.breaks.base,
            z.labels = acc.labels.base,
            contour = F) +
  facet_grid(entropy ~ manip) -> g.base

# DIFFERENCE
df.plot.maths %>%
  filter(manip == "diff") %>% 
  mutate(manip = "THEORETICAL – REORDERED") %>% 
  plot.base(col.pal = col.pal.diff,
            z.breaks = acc.breaks.diff,
            z.labels = acc.labels.diff,
            contour = F) +
  facet_grid(entropy ~ manip) +
  theme(axis.title.y = element_blank(),
        strip.text = element_text(vjust = 0)) -> g.diff

# ASSEMBLE
(g.base + g.diff + plot_layout(widths = c(2, 1))) +
  plot_annotation(tag_levels = c("a","b")) &
  theme(plot.tag.position = c(0, 1),
        plot.tag = element_text(size = 14, hjust = 0, vjust = 1, face = "bold")) -> g

g

if (save) {
  g %>% ggsave(filename = "./figures/fig3.png", width = 8, height = 3, dpi = 300, device = ragg::agg_png)
}
```

**Figure 3.** Based on the transition matrix used to generate sequences of stimuli and the confusion matrix of a classifier trained on random sequence data, it is possible to calculate the expected accuracy of the classifier when tested on structured sequences. The results align closely with the accuracy measured from reordered random data (see figure 2a).

### Plot "Matters Arising"

#### Build accuracy plots

```{r}
## Aggregate all data and clean

df.plot.maths <- bind_rows( 
  # --- make datasets compatible
  df.maths.mean %>% mutate(manip = "maths") %>% 
    mutate(t_train = dt*(t_train-1) - 0,
           t_test = dt*(t_test-1) - 680),
  df.stim.mean %>% 
    filter(manip == "") %>% 
    mutate(manip = "original") %>% 
    mutate(entropy = toupper(sub("rd_to_", "", direction))) %>% 
    mutate(across(starts_with("t_"), ~(dt*(.-1)-700))) %>% 
    select(-stim, -direction)
) %>% 
  # --- calculate difference
  pivot_wider(names_from = manip, values_from = "accuracy") %>%
  mutate(diff = original - maths) %>%
  pivot_longer(cols = c(original, maths, diff),
               names_to = "manip", values_to = "accuracy") %>% 
  # --- crop time window
  filter(t_train>=0, (t_train-333) < dt) %>% 
  # --- aggregate results of cluster analysis
  left_join(df.clusters.maths %>%
              mutate(t_train = dt*(t_train-1) - 0,
                     t_test = dt*(t_test-1) - 680)
  ) %>% 
  # --- clean labels
  mutate(manip = (recode_factor(manip, original = "REPLICATION\n", maths = "THEORETICAL NULL\n",
                                diff = "REPLICATION – THEORETICAL NULL\n")),
         direction = factor(entropy, levels = rev(c("RD","MM","MP","OR"))))
```


```{r}
## PLOT
# Initialize subplots
g.maths.base <- list()
g.maths.diff <- list()

# --- ORIGINAL & THEORETICAL NULL
df.plot.maths %>% 
  filter(manip != "REPLICATION – THEORETICAL NULL\n") %>% 
  # mutate(manip = ifelse(manip=="ORIGINpaste0("Test data: ", manip)) %>% 
  plot.base(col.pal = col.pal.base,
            z.breaks = acc.breaks.base,
            z.labels = acc.labels.base) +
  facet_grid(direction ~ manip) -> g
  # scale_x_continuous(breaks = seq(-600,600,100))
  # labs(title = paste0("Trials: ", toupper(s), " / Decoded: PRESENTED stimulus"))

g.maths.base[["acc"]] <- g %>% add_onset(df.labels.onset.stim %>% 
                                           mutate(manip = str_replace(manip, "EMPIRICAL","THEORETICAL")))

# --- DIFFERENCE
df.plot.maths %>%
  filter(manip == "REPLICATION – THEORETICAL NULL\n") %>% 
  plot.base(col.pal = col.pal.diff,
            z.breaks = acc.breaks.diff,
            z.labels = acc.labels.diff) +
  facet_grid(direction ~ manip) +
  # scale_x_continuous(breaks = seq(-600,600,100)) +
  # labs(title = paste0("Trials: ", toupper(s))) +
  theme(axis.title.y = element_blank()) -> g

g.maths.diff[["acc"]] <- g %>% add_onset(df.labels.onset.stim %>% 
                                           mutate(manip = str_replace(manip, "EMPIRICAL","THEORETICAL")))

g.fig1.2.acc <- (
  g.maths.base[["acc"]] + 
    (g.maths.diff[["acc"]]  + plot_layout(tag_level = "new")) +
    plot_layout(widths = c(2, 1)) &
    theme(strip.text.x = element_text(face = "bold"))
  )

g.fig1.2.acc
```

#### Build correlations plots

```{r}
df.plot <- df.plot.maths.corr %>% 
  mutate(manip = str_replace(manip, "ORIGINAL", "REPLICATION"),
         manip = paste0(manip, "\n"))

# ORIGINAL & THEORETICAL
df.plot %>% 
  filter(manip != "REPLICATION – THEORETICAL NULL\n") %>% 
  # mutate(manip = paste0("Test data: ", manip)) %>% 
  mutate(direction = "") %>% 
  plot.base(col.pal = col.pal.corr,
            z = "r",
            z.breaks = corr.breaks,
            z.labels = corr.labels) +
  # scale_x_continuous(breaks = seq(-600,600,100)) +
  labs(fill = "Correlation") +
  facet_grid(direction ~ manip) -> g

g.maths.base[["corr"]] <- g %>% add_onset(df.labels.onset.stim %>% 
                                            mutate(direction = "") %>% 
                                            mutate(manip = str_replace(manip, "EMPIRICAL","THEORETICAL")))

# DIFFERENCE
df.plot %>%
  filter(manip == "REPLICATION – THEORETICAL NULL\n") %>% 
  mutate(direction = "") %>% 
  plot.base(col.pal = col.pal.corr,
            z = "r",
            z.breaks = corr.breaks,
            z.labels = corr.labels) +
  facet_grid(. ~ manip) +
  # scale_x_continuous(breaks = seq(-600,600,100)) +
  labs(fill = "Correlation") +
  # labs(title = paste0("Trials: ", toupper(s))) +
  theme(axis.title.y = element_blank()) -> g


g.maths.diff[["corr"]] <- g %>% add_onset(df.labels.onset.stim %>% 
                                            mutate(direction = "") %>% 
                                            mutate(manip = str_replace(manip, "EMPIRICAL","THEORETICAL")))

g.fig1.2.corr <- (
  g.maths.base[["corr"]] + 
    (g.maths.diff[["corr"]] + plot_layout(tag_level = "new")) +
    plot_layout(widths = c(2, 1)) &
    theme(strip.text.x = element_blank())
  )

g.fig1.2.corr
```

## PREDICTING MOST LIKELY

### Load data

```{r}
#| cache: true
tic()

# Load subject-level data and derive grand average
df.stim.ml.mean <- tibble()
df.stim.ml.subj <- tibble()
for (manip in c("","_reord")) { 
  
  for (direction in c("rd_to_mm", "rd_to_mp", "rd_to_or")) {
    
    tmp <- load_loop_subj(folder = "reorder_random",
                          condition = paste0(direction, "_sp", manip))
    
    df.stim.ml.mean %<>% bind_rows(tmp[[2]] %>% mutate(manip = manip, direction = direction))
    df.stim.ml.subj %<>% bind_rows(tibble(manip = manip, direction = direction, array = list(tmp[[1]])))
  }
}

df.stim.ml.mean %<>% mutate(stim = "sounds")
df.stim.ml.subj %<>% mutate(stim = "sounds") %>% mutate(array = map(array, .f=\(x){x-0.25}))

toc() # ~ 30s
```

### Correlations with entropy
```{r}
tic()

## Prepare input data
df.tmp <- df.stim.ml.subj %>% 
  calculate_diff(f.map = map2, values_to = "array") %>%
  mutate(entropy = str_remove(direction, "rd_to_"),
         entropy = factor(entropy, levels = c("rd","mm","mp","or"))) %>% 
  select(-direction) %>% 
  arrange(as.numeric(entropy))
df.tmp


## Calculate correlations
df.corr.ml.mean <- tibble()
df.corr.ml.subj <- tibble() 
# --- Loop through condition "manip" and stimulus type "stim"
for (mm in c("original","reordered","diff")) { 
  print(mm)
  for (ss in c("sounds")) {
    print(ss)
    
    # --- Loop through subjects to derive a 3D array of participant-level time-generalized correlations with entropy, from a 3D array of participant-level accuracy matrix
    for (idx.subj in 1:n.subj) {
      
      # --- bind time-generalization matrices for the 3 non-random conditions into a single 3D array
      arr.tmp <- correlations_extract3D(data = filter(df.tmp, manip == mm, stim == ss),
                                        idx.lines = 1:3, idx.subj)
      # arr.tmp <- abind(
      #   filter(df.tmp, manip == mm, stim == ss)[[1,"array"]][[1]][,,idx.subj],
      #   filter(df.tmp, manip == mm, stim == ss)[[2,"array"]][[1]][,,idx.subj],
      #   filter(df.tmp, manip == mm, stim == ss)[[3,"array"]][[1]][,,idx.subj],
      #   along = 3)
      
      # --- calculate correlation with entropy level coded as 0,1,2, obtaining a 2D array
      arr.corr.tmp <- apply(arr.tmp, 1:2, correlations_vecs, vec = 0:2)
      
      # --- append to already processed subjects in a 3D array
      if (idx.subj == 1) {
        arr.corr <- arr.corr.tmp
      } else {
        arr.corr %<>% abind(arr.corr.tmp, along = 3)
      }
    }
    
    # Replace NAs by 0 and extreme values by +/- .99
    arr.corr <- correlations_fixval(arr.corr)
    
    # --- store participant-level results in a dataframe
    df.corr.ml.subj %<>% bind_rows(tibble(manip = mm, stim = ss, array = list(arr.corr)))
    
    # --- calculate groupe average and store in a dataframe
    df.corr.ml.mean %<>% bind_rows(
      arr.corr %>% 
        atanh %>%  # apply Fisher's transformation
        apply(c(1,2), mean) %>% # average across participants
        tanh %>% # convert back to correlation coefficients  
        matrix_to_df2(row.name = "t_train", col.name = "t_test", val.name = "r") %>% 
        mutate(manip = mm, stim = ss)
    )
  }
}

toc() # ~ 1min
```


### Cluster stats

#### Accuracy

```{r}
#| cache: true
tic()

## Cluster analysis with subject-level data
# --- calculate original-reordered difference
tmp.diff <- df.stim.ml.subj %>% 
  calculate_diff(f.map = map2, values_to = "array")
# --- calculate average of differences
tmp.ave <- tmp.diff %>% 
  filter(manip == "diff") %>% 
  pivot_wider(names_from = direction, values_from = array) %>% 
  group_by(stim, manip) %>% 
  summarise(array = pmap(., .f=function(rd_to_mm, rd_to_mp, rd_to_or, ...) {(rd_to_mm+rd_to_mp+rd_to_or)/3})) %>% 
  mutate(direction = "average of\n(MM,MP,OR)")
# --- combine & run cluster analysis
df.clusters.ml <- bind_rows(tmp.diff, tmp.ave) %>% 
  cluster_loop_cond(n_permutations = 5000)

## Grand average data
# --- calculate original-reordered difference
tmp.diff <- df.stim.ml.mean %>%
  calculate_diff(f.map = map2_dbl, values_to = "accuracy")
# --- calculate average of difference across entropy levels
tmp.ave <- tmp.diff %>% 
  filter(manip == "diff") %>% 
  group_by(t_train, t_test, manip, stim) %>% 
  summarise(accuracy = mean(accuracy, na.rm=T)) %>% 
  mutate(direction = "average of\n(MM,MP,OR)")
# --- combine
df.plot.ml <- bind_rows(tmp.diff, tmp.ave)

##  Aggregate all data and clean
df.plot.ml %<>%
  # --- append cluster significance
  left_join(df.clusters.ml) %>%
  mutate(manip = (recode_factor(manip, original = "ORIGINAL", reordered = "REORDERED",
                                diff = "ORIGINAL – REORDERED"))) %>%
  mutate(direction = toupper(sub("rd_to_", "", direction))) %>% 
  mutate(direction = factor(direction, levels = rev(c("AVERAGE OF\n(MM,MP,OR)","MM","MP","OR")))) %>%
  # --- convert indices to time
  mutate(across(starts_with("t_"), ~(dt*(.-1)-700))) %>%
  # --- crop time
  filter(t_train>=0, (t_train-333) < dt)

toc() # ~3.5min
```

#### Correlations

```{r}

tic()
df.clusters.corr.ml <- df.corr.ml.subj %>% 
  cluster_loop_cond(n_permutations = 5000)
toc() # ~ 2.5min

# --- append cluster significance
df.plot.ml.corr <- df.corr.ml.mean %>% 
  left_join(df.clusters.corr.ml) %>%
  mutate(manip = (recode_factor(manip, original = "ORIGINAL", reordered = "REORDERED",
                                diff = "ORIGINAL – REORDERED"))) %>% 
  #mutate(direction = toupper(sub("rd_to_", "", direction)),
  #       direction = factor(direction, levels = rev(c("RD","MM","MP","OR")))) %>%
  # --- convert indices to time
  mutate(across(starts_with("t_"), ~(dt*(.-1)-700))) %>%
  # --- crop time
  filter(t_train>=0, (t_train-333) < dt)

df.plot.ml.corr

```

### Plot v1

```{r}
#| fig-width: 8
#| fig-height: 4
#| column: page
#| lightbox:
#|   group: r-graph

# ORIGINAL & REORDERED
df.plot.ml %>% 
  filter(manip != "ORIGINAL – REORDERED") %>% 
  mutate(manip = paste0("Test data: ", manip)) %>% 
  # mutate(manip = case_match(manip, ""~"Test data: ORIGINAL",
  #                           "_reord"~"Test data: RANDOM REORDERED")) %>% 
  plot.base(col.pal = col.pal.base,
            z.breaks = acc.breaks.base,
            z.labels = acc.labels.base) +
  facet_grid(direction ~ manip) +
  labs(title = paste0(toupper("sounds"), ", decoding most likely")) -> g.base

# DIFFERENCE & AVERAGE
df.plot.ml %>%
  filter(manip == "ORIGINAL – REORDERED") %>% 
  plot.base(col.pal = col.pal.diff,
            z.breaks = acc.breaks.diff,
            z.labels = acc.labels.diff) +
  facet_grid(direction ~ manip) +
  labs(title = toupper("sounds")) +
  theme(axis.title.y = element_blank(),
        strip.text = element_text(vjust = 0)) -> g.diff

# ASSEMBLE
(g.base + g.diff + plot_layout(widths = c(2, 1))) +
  plot_annotation(tag_levels = c("a","b")) &
  theme(plot.tag.position = c(0, 1),
        plot.tag = element_text(size = 14, hjust = 0, vjust = 1, face = "bold")) -> g

g

if (save) {
  g %>% ggsave(filename = "./figures/fig4.png", width = 8, height = 4, dpi = 300, device = ragg::agg_png)
}
```

**Figure 4.** Time-generalization decoding of the sound most likely to be presented at t=0, given the identity of the previous sound, with a classifier trained on random sequence data. Compared to the original approach (replicated here in figure 2a, left), this approach tests the more plausible hypothesis that the brain holds the strongest predictive representation for the most statistically likely stimulus, which is not always the actually presented one (see Methods and figure 1d). **(a)** Direct comparison of decoding performance with the 25% chance level appear to suggest negative performance, but this is largely due to statistical dependency between the the most likely and the actual sound, as is confirmed by decoding reordered random sequences. **(b)** After proper control of statistical dependency effects, a robust but weak (\<1% point) above chance level decoding remains between +80 and +230ms.

### Plot "Matters Arising"

```{r}
g.base.ml <- list()
g.diff.ml <- list()
```


#### Build accuracy plots

```{r}

for (s in c("sounds")) {
  # ORIGINAL & REORDERED
  df.plot.ml %>% 
    filter(t_test >=-333, t_test <= 0) %>% 
    filter(stim == s, manip != "ORIGINAL – REORDERED") %>% 
    mutate(manip = paste0(manip)) %>% #"Test data: ", 
    plot.base(col.pal = col.pal.base,
              z.breaks = acc.breaks.base,
              z.labels = acc.labels.base,
              legend.position = "right") +
    facet_grid(direction ~ manip) +
    labs(title = paste0("Trials: ", toupper(s), " / Decoded: MOST LIKELY")) +
    theme(plot.title = element_text(hjust = -0.2)) -> g.base.ml[["acc"]][[s]]
  
  # DIFFERENCE
  df.plot.ml %>%
    filter(t_test >=-333, t_test <= 0) %>% 
    filter(!grepl("AVERAGE",direction)) %>% 
    filter(stim == s, manip == "ORIGINAL – REORDERED") %>% 
    mutate(manip = "DIFF") %>% 
    plot.base(col.pal = col.pal.diff,
              z.breaks = acc.breaks.diff,
              z.labels = acc.labels.diff,
              legend.position = "right") +
    facet_grid(direction ~ manip) +
    # labs(title = paste0("Trials: ", toupper(s))) +
    theme(axis.title.y = element_blank()) -> g.diff.ml[["acc"]][[s]]
}

(g.base.ml[["acc"]][["sounds"]] + (g.diff.ml[["acc"]][["sounds"]] + plot_layout(tag_level = "new")) + plot_layout(widths = c(2, 1))) + 
  theme(plot.tag.position = c(0, 1)) -> g.fig2.acc

g.fig2.acc
```

#### Build correlations plots

```{r}

for (s in c("sounds")) {
  # ORIGINAL & REORDERED
  df.plot.ml.corr %>% 
    filter(t_test >=-333, t_test <= 0) %>% 
    filter(stim == s, manip != "ORIGINAL – REORDERED") %>% 
    mutate(manip = paste0(manip)) %>% #"Test data: ", 
    mutate(direction = "") %>% 
    plot.base(col.pal = col.pal.corr,
              z = "r",
              z.breaks = corr.breaks,
              z.labels = corr.labels,
              legend.position = "right") +
    labs(fill = "Correlation") +
    facet_grid(direction ~ manip) -> g.base.ml[["corr"]][[s]]
  
  # DIFFERENCE
  df.plot.ml.corr %>%
    filter(t_test >=-333, t_test <= 0) %>% 
    filter(stim == s, manip == "ORIGINAL – REORDERED") %>%
    mutate(manip = "DIFF") %>% 
    mutate(direction = "") %>%
    plot.base(col.pal = col.pal.corr,
              z = "r",
              z.breaks = corr.breaks,
              z.labels = corr.labels,
              legend.position = "right") +
    facet_grid(. ~ manip) +
    labs(fill = "Correlation") +
    # labs(title = paste0("Trials: ", toupper(s))) +
    theme(axis.title.y = element_blank()) -> g.diff.ml[["corr"]][[s]]
}

(g.base.ml[["corr"]][["sounds"]] + g.diff.ml[["corr"]][["sounds"]] + plot_layout(widths = c(2, 1))) +
  # plot_annotation(tag_levels = list("b.")) &
  theme(plot.tag.position = c(0, 1)) -> g.fig2.corr

g.fig2.corr
```

#### Combine into figure 2

```{r, fig.width = 8, fig.height = 5.5}
(g.mostlikely) +
  plot_spacer() +
  ((g.fig2.acc / (g.fig2.corr + plot_layout(tag_level = 'new'))) + 
     plot_layout(heights = c(3, 1)) & 
     theme(plot.title = element_text(vjust = -8),
           legend.box.margin = margin(l=-5),
           strip.clip = "off",
           axis.text.x = element_text(angle = 45, hjust = 1))
  ) + 
  plot_layout(widths = c(1, 0.1, 2)) +
  plot_annotation(tag_levels = "a") & 
  theme(plot.tag.position = c(0, 1),
        plot.tag = element_text(vjust = 3)) -> g

if (save) {
  g %>% ggsave(filename = "./figures/fig2_MattersArising.png", width = 8, height = 5.5, dpi = 300, device = ragg::agg_png)
}
```


## Figure 5

### Load data

```{r}
#| cache: true

# df.trainintest <- tibble()
# for (manip in c("","_reord")) { 
#   
#   for (entropy in tolower(names(mat.T))) {
#     
#     df.trainintest %<>% bind_rows(
#       load_loop_subj(folder = "reorder_random",
#                      condition = paste0(entropy,"_to_",entropy,manip)) %>% 
#         mutate(manip = manip, entropy = entropy)
#     )
#   }
# }

df.traineqtest.mean <- tibble()
df.traineqtest.subj <- tibble()
for (manip in c("","_reord")) { 
  
  for (entropy in tolower(names(mat.T))) {
    
      tmp <- load_loop_subj(folder = "reorder_random",
                     condition = paste0(entropy, manip, "_to_", entropy, manip),
                     group.mean = FALSE, diag = TRUE)
      
      df.traineqtest.mean %<>% bind_rows(
        tmp[[2]] %>% mutate(manip = manip, entropy = entropy)
        )
      df.traineqtest.subj %<>% bind_rows(
        tibble(manip = manip, entropy = entropy, array = list(tmp[[1]]))
        )
  }
}
```

### Prepare data

```{r}

# Factorize & filter
df.plot.teqt <- df.traineqtest.mean %>% 
  mutate(entropy = factor(toupper(entropy), levels = rev(names(mat.T)))) %>% 
  # --- convert indices to time
  mutate(across(starts_with("t_"), ~(dt*(.-1)-700)))
  

# Add difference scores
df.plot.teqt %<>% 
  mutate(manip = case_match(manip, "" ~ "original", "_reord" ~ "reordered")) %>% 
  pivot_wider(names_from = manip, values_from = accuracy) %>%
  mutate(diff = original - reordered) %>% 
  pivot_longer(cols=c(original,reordered,diff),
               names_to = "manip", values_to = "accuracy") %>% 
  mutate(manip = (recode_factor(manip, original = "original", reordered = "reordered",
                                diff = "original – reordered",)))

# Calculate group mean & CIs
df.plot.teqt %<>%
  group_by(t_train, entropy, manip) %>% 
  summarise(accuracy.ci = 2*sd(accuracy)/sqrt(n.subj),
            accuracy.mean = mean(accuracy),
            .groups = "drop")
```

### Plot

This one trains on entropy data and tests on random-reordered:

```{r}
#| column: page
#| lightbox:
#|   group: r-graph

df.plot.teqt %>% 
  ggplot(aes(x = t_train, y = accuracy.mean, color = entropy, fill = entropy)) +
  facet_grid(manip ~ ., scales = "free_y") +
  geom_hline(data = tibble(manip = factor(c("original", "reordered", "original – reordered"),
                                          levels = levels(df.plot$manip)),
                           chance = c(.25, .25, 0)),
             aes(yintercept = chance)) +
  geom_ribbon(aes(ymin = accuracy.mean-accuracy.ci, ymax = accuracy.mean+accuracy.ci),
              color = NA,
              alpha = 0.3) +
  geom_line() +
  geom_vline(xintercept = 0, color = col.lines) +
  geom_vline(xintercept = 333*c(-2,-1,1,2), linetype = 2, color = col.lines) +
  scale_x_continuous(name = " peri-stimulus time (ms)",
                     breaks = scales::pretty_breaks(8)) +
  labs(title = "Train & test on same condition data",
       subtitle = "Only test data is reordered",
       y = "accuracy")
```

**Figure 5.** Decoding of sounds in structured sequences with a classifier trained on the same sequences. During the presentation of the stimulus itself (t between 0 and 333ms), all classifiers have the exact same performance on random sequence data ??? \<- this is not expected: the random classifier should perform better than all others, as it is better tuned to random data (same logic than behind the negative diagonal in figure 2b)

# Supplementary figures

## Confusion matrices

### Single subject, single time point
```{r, fig.width = 6, fig.height = 2.3}

mat.C.all <- array(dim = c(34,34,4,4,n.subj))
i <- 1

for (s in list.subj) {
    
    # --- load the confusion matrix
    tmp.file <- os$path$join(path.root, s, "reorder_random", "rd_to_rd_confmats.npz") %>%
      np$load()
    
    # --- crop around S0 (decoded stimulus)
    mat.C.all[,,,,i] <- tmp.file$f[["arr_0"]][,71:104,71:104,,] %>%
      apply(c(2,3,4,5), mean)
    
    i <- i+1
}

mat.C.mean <- mat.C.all %>% apply(c(1,2,3,4), mean)

    
df.confusion <- matrix_to_df2(matC.mean[22,22,,], "from", "to", "p") %>% 
  mutate(label = paste0("a[",from,to,"]"))
df.confusion %>% 
  ggplot(aes(x = to, y = from, fill = p)) +
  geom_tile(color = "firebrick3") + 
  geom_text(aes(label = label), parse = T, color = "firebrick3") +
  scale_x_continuous(name = "predicted class", position = "top") +
  scale_y_reverse(name = "true class") +
  scale_fill_stepsn(name = "p",
                    colors = pals::brewer.greys(100),
                      # low = "white", high = "black",
                      labels = ~str_replace(., "^0.","."),
                      breaks = scales::pretty_breaks(6),
                      limits = c(.20,.30), oob = scales::squish) +
  coord_equal(xlim = c(0.5,4.5), ylim = rev(c(0.5,4.5)),
              expand = F, clip = "off") -> g.matC

matrix_to_df2(mat.T$MP, "from", "to", "p") %>% 
  mutate(label = paste0("a[",from,to,"]")) %>% 
  ggplot(aes(x = to, y = from, fill = p)) +
  geom_tile(color = "firebrick3") + 
  geom_text(aes(label = label), parse = T, color = "firebrick3") +
  scale_x_continuous(name = "to", position = "top") +
  scale_y_reverse(name = "from") +
  scale_fill_stepsn(name = "p",
                    colors = pals::brewer.greys(100),
                      labels = ~str_replace(., "^0.","."),
                      breaks = scales::pretty_breaks(6),
                      limits = c(.0,.50), oob = scales::squish) +
  coord_equal(xlim = c(0.5,4.5), ylim = rev(c(0.5,4.5)),
              expand = F, clip = "off") -> g.matT

 
(g.matT + labs(caption = "Transition matrix\n(midplus (MP) sequence)") +
    guides(fill = guide_colorbar(barwidth = 0.5, ticks = F))) +
(g.matC + labs(caption = "Confusion matrix\n(group average, t=210ms)") +
    guides(fill = guide_colorbar(barwidth = 0.5, ticks = F))) &
  theme(plot.caption = element_text(size = 10),
        axis.title = element_text(face = "italic"),
        legend.box.spacing = unit(2,"mm"),
        )
  # plot_annotation(tag_levels = "a")

# Other visualization style
df.plot <- left_join(matrix_to_df2(matC.mean[22,22,,], "from", "to", "C"),
                     matrix_to_df2(mat.T$MP, "from", "to", "T")) %>% 
  pivot_longer(names_to = "matrix", values_to = "p", cols = c(C,T))

df.plot %>% 
  ggplot(aes(x = to, y = p, fill = matrix)) +
  facet_grid(rows = "from")  +
  geom_hline(yintercept = .25) +
  geom_col(position = "dodge")
```

### Group average, multiple time points
```{r}
#| fig-width: 6
#| fig-height: 2
#| column: page
#| lightbox:
#|   group: r-graph

df.confusion <- tibble()
for (i in 1:dim(mat.C.mean)[1]) {
  df.confusion %<>% bind_rows(
    mat.C.mean[i,i,,] %>% matrix_to_df2("from", "to", "p") %>% mutate(t = i)
  )
}

df.confusion %>% 
  mutate(t = dt*(t-1)) %>% 
  filter(t%%30==0) %>% 
  ggplot(aes(x = to, y = from, fill = p)) +
  facet_wrap(~ t, ncol = 6, labeller = label_both, strip.position = "bottom") +
  geom_tile() + 
  scale_x_continuous(name = "predicted class", position = "top") +
  scale_y_reverse(name = "true class") +
  scale_fill_gradient2(name = "transition probability",
                      low = "white", high = "black",
                      labels = ~str_replace(., "^0.","."),
                      limits = c(0.15,0.35), oob = scales::squish) +
  guides(fill = guide_colorbar(barwidth = 0.5,
                               ticks = F, title.vjust = 1)) +
  coord_equal(xlim = c(0.5,4.5), ylim = rev(c(0.5,4.5)),
              expand = F, clip = "off") +
  theme()
```
